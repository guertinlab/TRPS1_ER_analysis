---
title: \sf TRPS1-ER Analysis Vignette 
header-includes:
- \usepackage{color}
- \usepackage{float}
- \DeclareUnicodeCharacter{2212}{-}
output:
  bookdown::html_document2:
    toc: true
fontsize: 14pt
geometry: margin=1in
date: "Last compiled on `r format(Sys.time(), '%d %B %Y')`"
---

```{css, echo=FALSE}
body .main-container {
  max-width: 1600px !important;
  width: 1600px !important;
}
body {
  max-width: 1600px !important;
}

pre {
  max-height: 600px;
  overflow-y: auto;
}

pre[class] {
  max-height: 600px;
}
```

# Introduction

This is a work in progress. 

# GWAS summary statistics processing

## Make the file to upload to LocusZoom (Figure 1A)

Here we just focus on chromosome 8 (where TRPS1 is located) and a subset of columns to keep the file size manageable.
I uploaded this file to LocusZoom to make the plot.

```{r engine='bash', eval=F, echo=TRUE}
wget https://bcac.ccge.medschl.cam.ac.uk/files/icogs_onco_gwas_meta_overall_breast_cancer_summary_level_statistics.txt.zip
unzip icogs_onco_gwas_meta_overall_breast_cancer_summary_level_statistics.txt.zip
head -n 1 icogs_onco_gwas_meta_overall_breast_cancer_summary_level_statistics.txt > Breast_cancer_GWAS_PMID_32424353_chr8.txt
grep '^8_' icogs_onco_gwas_meta_overall_breast_cancer_summary_level_statistics.txt >> Breast_cancer_GWAS_PMID_32424353_chr8.txt
awk '{OFS = "\t"; print $9, $10, $41, $40, $46}' Breast_cancer_GWAS_PMID_32424353_chr8.txt > Breast_cancer_GWAS_PMID_32424353_chr8_subset.txt
```

# Cancer Dependency Map data processing

## Download the data

I downloaded the 22Q1 data release from the DepMap portal, with the TRPS1 and ESR1 CRISPR gene effect (Chronos) scores for all cell lines. I also downloaded the list of annotated luminal breast cancer cell lines from the DepMap portal as of March 13, 2022.

## Plot the data (Figure 1B,C)

Set up in R. R code chunks will be in light blue, to distinguish from bash code chunks in grey.

```{r class.source="bg-info", engine='R', eval=F, echo=T}
setwd("~/Library/CloudStorage/Box-Box/GuertinLab/DepMap/")
library(tidyverse)
library(dplyr)
library(ggrepel)
library(ggsignif)
`%notin%` <- Negate(`%in%`)
```

Read in the data.

```{r class.source="bg-info", engine='R', eval=F, echo=T}
Chronos <- read_csv("Chronos.csv")
colnames(Chronos)[c(2,3)] <- c("ESR1", "TRPS1")
Luminal <- read_csv("cell lines in luminal.csv")
Chronos_luminal_last <- rbind.data.frame(Chronos[Chronos$`DepMap ID` %notin% Luminal$`Depmap Id`,],
                                         Chronos[Chronos$`DepMap ID` %in% Luminal$`Depmap Id`,])
cols = ifelse(Chronos_luminal_last$`DepMap ID` %in% Luminal$`Depmap Id`, "red", "black")
```

Plot.

```{r class.source="bg-info", engine='R', eval=F, echo=T}
pdf("Chronos_ESR1_vs_TRPS1_Luminal.pdf")
ggplot(Chronos_luminal_last, aes(x = ESR1, y = TRPS1, color = cols)) +
  geom_point() +
  scale_color_manual(values = c("black", "red")) +
  geom_text_repel(aes(label=ifelse(`DepMap ID` %in% Luminal$`Depmap Id`, 
                                   as.character(`Cell Line Name`),'')),
                  max.overlaps = nrow(Chronos_luminal_last)) + 
  xlab("ESR1 knockout score") +
  ylab("TRPS1 knockout score") +
  coord_fixed(ratio = 1, xlim = c(-1.2, 0.5), ylim = c(-1.2, 0.5)) +
  theme_bw() +
  theme(text = element_text(size = 20), legend.position="none")
dev.off()

pdf("Chronos_TRPS1_score_by_class.pdf")
ggplot(Chronos_luminal_last, aes(x = cols, y = TRPS1, color = cols)) +
  geom_violin() +
  geom_boxplot(width=.1) +
  #geom_signif(comparisons = list(c("black", "red")), map_signif_level=F)
  geom_hline(yintercept = 0, linetype="dashed") +
  scale_color_manual(values = c("black", "red")) +
  ylim(-1.2, 0.5) +
  ylab("TRPS1 knockout score") +
  xlab("Cell line class") +
  theme_bw() +
  theme(legend.position="none")
dev.off()
```

T-tests.

```{r class.source="bg-info", engine='R', eval=F, echo=T}
#0.002235
t.test(Chronos_luminal_last$TRPS1[cols == "red"],
       Chronos_luminal_last$TRPS1[cols == "black"])
#3.204e-05
wilcox.test(Chronos_luminal_last$TRPS1[cols == "red"],
       Chronos_luminal_last$TRPS1[cols == "black"])
```

# ChIP-seq data pre-processing 

## Set up

Log in to the cluster to perform the processing for each sample in parallel. 

```{r engine='bash', eval=F, echo=TRUE}
ssh -Y ts2hx@rivanna.hpc.virginia.edu
ijob -A gioeli_lab -p standard --cpus-per-task=10 --time=8:00:00
module load sratoolkit/2.10.5
vdb-config -i #press x to exit
```

Make directories for the later scripts to write files.

```{r engine='bash', eval=F, echo=TRUE}
title=ChIP
scripts=/scratch/ts2hx/scripts
main=/scratch/ts2hx/${title}/results

mkdir -p /scratch/ts2hx/${title}/logs
mkdir -p /scratch/ts2hx/${title}/raw_data
mkdir -p ${main}/fastqc
mkdir -p ${main}/bowtie2/controls
mkdir -p ${main}/macs2
mkdir -p ${main}/meme
mkdir -p ${main}/chipqc/meta
mkdir -p ${main}/chipqc/bams
mkdir -p ${main}/counts
mkdir -p ${main}/bigWigs
```

Get the required script for bigWig merging and move to a directory that will end up in the $PATH.

```{r engine='bash', eval=F, echo=TRUE}
wget https://raw.githubusercontent.com/guertinlab/Nascent_RNA_Methods/main/normalize_bedGraph.py
chmod +x normalize_bedGraph.py
mv normalize_bedGraph.py $HOME/bin/
```

Get the ENCODE blacklist.

```{r engine='bash', eval=F, echo=TRUE}
wget https://raw.githubusercontent.com/Boyle-Lab/Blacklist/master/lists/hg38-blacklist.v2.bed.gz -P $HOME/hg38/
gunzip $HOME/hg38/hg38-blacklist.v2.bed.gz
mv $HOME/hg38/hg38-blacklist.v2.bed $HOME/hg38/hg38.blacklist.bed
```

## Download the raw data from both sequencing runs, rename the files, and combine the reads

Download the first run.

```{r engine='bash', eval=F, echo=TRUE}
cd /scratch/ts2hx/${title}/raw_data

wget http://guertinlab.cam.uchc.edu/230302_tgs_pool1.zip
md5sum 230302_tgs_pool1.zip
unzip 230302_tgs_pool1.zip

wget http://guertinlab.cam.uchc.edu/230306_tgs_pool2.zip
md5sum 230306_tgs_pool2.zip
unzip 230306_tgs_pool2.zip
#There are no "x" samples in this pool
rm -r *_x_*
```

Rename files to remove the excess.

```{r engine='bash', eval=F, echo=TRUE}
for i in *_R1_001.fastq.gz
do
  name=$(echo $i | awk -F"_S[0-9]" '{print $1}')
  echo $name
  mv ${name}_*_R1_001.fastq.gz ${name}_PE1.fastq.gz
  mv ${name}_*_R2_001.fastq.gz ${name}_PE2.fastq.gz
done
```

Download the second run.

```{r engine='bash', eval=F, echo=TRUE}
wget http://guertinlab.cam.uchc.edu/230320_tgs_ChIP_pool1.zip
md5sum 230320_tgs_ChIP_pool1.zip
unzip 230320_tgs_ChIP_pool1.zip
wget http://guertinlab.cam.uchc.edu/230321_TGS_ChIP_pool2.zip
md5sum 230321_TGS_ChIP_pool2.zip
unzip 230321_TGS_ChIP_pool2.zip
#There are no "x" samples in this pool
rm -r *_x_*
```

Combine the reads.

```{r engine='bash', eval=F, echo=TRUE}
for i in *_R1_001.fastq.gz
do
  name=$(echo $i | awk -F"_S[0-9]" '{print $1}')
  echo $name
  cat ${name}_*_R1_001.fastq.gz ${name}_PE1.fastq.gz > ${name}_tmp.fastq.gz
  mv ${name}_tmp.fastq.gz ${name}_PE1.fastq.gz
  rm ${name}_*_R1_001.fastq.gz
  cat ${name}_*_R2_001.fastq.gz ${name}_PE2.fastq.gz > ${name}_tmp.fastq.gz
  mv ${name}_tmp.fastq.gz ${name}_PE2.fastq.gz
  rm ${name}_*_R2_001.fastq.gz
done
```

Some HA samples got 2 indices each, so combine them.

```{r engine='bash', eval=F, echo=TRUE}
for i in *_x_*
do
  factor=$(echo $i | awk -F"_" '{print $3}')
  treatment=$(echo $i | awk -F"_" '{print $4}')
  pre=$(echo $i | awk -F"_$factor" '{print $1}')
  post=$(echo $i | awk -F"_x_" '{print $2}')
  echo $factor
  echo $treatment
  echo $pre
  echo $post
  mv $i ${pre}_${factor}x_${treatment}_${post}
  mv ${pre}_${factor}_${treatment}_${post} ${pre}_${factor}y_${treatment}_${post}
  cat ${pre}_${factor}x_${treatment}_${post} ${pre}_${factor}y_${treatment}_${post} > \
    ${pre}_${factor}_${treatment}_${post}
done
```

## Process each sample

The script used in the next code chunk (230322_chipseq_analysis_on_input_file.sh) is below:

```{r engine='bash', eval=F, echo=TRUE}
#!/bin/bash/

# This script takes a gzip'd fastq file of ChIP-seq data, runs FastQC, removes adapters,
# and outputs a bam file for peak calling, a bed file for counting reads in peaks, 
# and a bigWig file for visualization.
# USAGE: sh chipseq_analysis_on_input_file.sh <path to the gzip'd PE1 file> <path to main results directory>

cores=$SLURM_CPUS_PER_TASK

#For fastq_pair
PATH=$HOME/bin:$PATH

#Change this to your main results directory
main=$2

#Change this to the location of the blacklist
blacklist=$HOME/hg38/hg38.blacklist.bed

# grab base of filename for naming outputs
name=`basename $1 _PE1.fastq.gz`
echo "Sample name is $name"

# grab the directory
dir=`dirname $1`
cd $dir

# directory with bowtie genome index
genome=/project/genomes/Homo_sapiens/UCSC/hg38/Sequence/Bowtie2Index/genome 

#Set up more variables for additional directories to help clean up the results folder
fastqc_out=${main}/fastqc/
bowtie_results=${main}/bowtie2
chipqc_out=${main}/chipqc/bams
counts_out=${main}/counts
bigWigs_out=${main}/bigWigs

#Set up the software environment
module load fastqc/0.11.5
module load cutadapt/3.4
module load gcc/9.2.0 pigz/2.4
module load bowtie2/2.2.9 
module load samtools/1.12
module load wigtobigwig/2.8
module load bedtools/2.29.2

#Unzip
gunzip ${name}_PE1.fastq.gz
gunzip ${name}_PE2.fastq.gz

#Run FastQC and move output to the appropriate folder
fastqc ${name}_PE1.fastq
fastqc ${name}_PE2.fastq
mv ${dir}/${name}_PE*_fastqc.* $fastqc_out

#Count raw reads for complexity estimate
raw_reads=$(wc -l ${name}_PE1.fastq | awk '{print $1/4}')
echo "Raw reads: $raw_reads"

#Remove adapters
cutadapt -j $cores -m 10 -O 1 -a AGATCGGAAGAGCACACGTCTGAACTCCAGTCA ${name}_PE1.fastq -o ${name}_PE1_noadap.fastq
cutadapt -j $cores -m 10 -O 1 -a AGATCGGAAGAGCGTCGTGTAGGGAAAGAGTGT ${name}_PE2.fastq -o ${name}_PE2_noadap.fastq

#Pair reads
reads=$(wc -l ${name}_PE1_noadap.fastq | awk '{print $1/4}')
fastq_pair -t $reads ${name}_PE1_noadap.fastq ${name}_PE2_noadap.fastq

#Align to the genome and keep concordantly aligned, unique reads
#Also print statistics on duplication rate and estimated library complexity
cd $bowtie_results
bowtie2 -p $((cores-5)) --maxins 1000 -x $genome \
  -1 ${dir}/${name}_PE1_noadap.fastq.paired.fq -2 ${dir}/${name}_PE2_noadap.fastq.paired.fq | \
  samtools view -bS -f 0x2 - | samtools sort -n - | samtools fixmate -m - - | samtools sort - | \
  samtools markdup -s -r - ${name}.bam
samtools index ${name}.bam

#Isolate PE1 for ChIPQC
samtools view -f 0x42 ${name}.bam -o ${chipqc_out}/${name}_ChIPQC.bam
samtools index ${chipqc_out}/${name}_ChIPQC.bam ${chipqc_out}/${name}_ChIPQC.bam.bai
  
#Convert bam to bed for counting
samtools sort -n ${name}.bam | bedtools bamtobed -i stdin -bedpe | \
  awk 'BEGIN { OFS = "\t"} { print $1, $2, $6, ".", "1" }' |
  grep -v "random" | grep -v "chrUn" | grep -v "chrEBV" | grep -v "chrM" | grep -v "alt" | \
  intersectBed -v -a stdin -b $blacklist | sort -k1,1 -k2,2n > ${counts_out}/${name}_not_scaled.bed

#Count resultant reads for complexity estimate
resultant_reads=$(wc -l ${counts_out}/${name}_not_scaled.bed | awk '{print $1}')
echo "Resultant reads: $resultant_reads"

#Zip and delete files
cd $dir
pigz -p $cores ${name}_PE1.fastq
pigz -p $cores ${name}_PE2.fastq
rm ${name}_*noadap*

#Deeptools wasn't loading python/numpy before, but purging and reloading helped (this may be unnecessary now)
module purge
module load deeptools/3.5.1

#Convert bam to bigWig for coverage visualization
#We re-do this later with a larger bin size, so this is not necessary here (should change in future)
bamCoverage --bam ${bowtie_results}/${name}.bam -o ${bigWigs_out}/${name}_not_scaled.bw -p $cores \
  --binSize 1 --extendReads --centerReads
```

Run the above script on each sample in parallel.

```{r engine='bash', eval=F, echo=TRUE}
chmod +x ${scripts}/230322_chipseq_analysis_on_input_file.sh
for fastq in *_HA*_PE1.fastq.gz *_ER_*_PE1.fastq.gz *_IgG_*_PE1.fastq.gz
do
  name=`basename $fastq _PE1.fastq.gz`
  fastq=/scratch/ts2hx/${title}/raw_data/${fastq}
  sbatch -p standard -A gioeli_lab -t 8:00:00 -N 1 -n 1 --cpus-per-task=10 --job-name chipseq-analysis \
    -o /scratch/ts2hx/${title}/logs/${name}_chipseq.log  \
    --wrap="sh ${scripts}/230322_chipseq_analysis_on_input_file.sh $fastq $main"
  sleep 1
done
```

Move IgG samples to subdirectory.

```{r engine='bash', eval=F, echo=TRUE}
cd ${main}/bowtie2/
mv *IgG*.bam* controls/
```

## Call peaks

The script used in the next code chunk (230308_macs2.sh) is below:

```{r engine='bash', eval=F, echo=TRUE}
#!/bin/bash
#Get the variables from the arguments
samples=$1
control=$2
factor=$3
main=$4

blacklist=$HOME/hg38/hg38.blacklist.bed

module load macs2/2.2.7.1 gcc/7.1.0 openmpi/3.1.4 intel/18.0 intelmpi/18.0 R/4.1.1 bedtools/2.26.0

macs2 callpeak -t ${samples}_*.bam -c ${control}_*.bam -f BAMPE -g hs -n $factor --keep-dup all \
  --outdir ${main}/macs2 

#Remove noncanonical chromosomes and blacklisted regions, and make a window of 50bp on either side of the summit
grep -v "random" ${main}/macs2/${factor}_summits.bed | grep -v "chrUn" | grep -v "chrEBV" | grep -v "chrM" | \
  intersectBed -v -a stdin -b $blacklist | slopBed -b 50 -i stdin -g $HOME/hg38/hg38.chrom.sizes > \
  ${main}/macs2/${factor}_summit_window.bed
```

Run the above script on each sample in parallel.

```{r engine='bash', eval=F, echo=TRUE}
#Call peaks for each factor 
chmod +x ${scripts}/230308_macs2.sh
for bam in *_DMSO_rep1.bam
do
  name=`basename $bam _DMSO_rep1.bam`
  factor=$(echo $name | awk -F"_" '{print $3}')
  samples=T47D_Clone28_${factor}
  control=controls/T47D_Clone28_IgG
  sbatch -p largemem -A gioeli_lab -t 4:00:00 -N 1 -n 1 --mem-per-cpu=64000 --job-name macs2 \
    -o /scratch/ts2hx/${title}/logs/${factor}_macs2.log \
    --wrap="sh ${scripts}/230308_macs2.sh $samples $control $factor $main"
  sleep 1
done
```

Remove noncanonical chromosomes and blacklisted regions. Could have added this to the macs2 script when I did it for the summit window. 

```{r engine='bash', eval=F, echo=TRUE}
blacklist=$HOME/hg38/hg38.blacklist.bed
module load gcc/9.2.0 bedtools/2.29.2
for bam in *_DMSO_rep1.bam
do
  name=`basename $bam _DMSO_rep1.bam`
  factor=$(echo $name | awk -F"_" '{print $3}')
  grep -v "random" ${main}/macs2/${factor}_peaks.narrowPeak | grep -v "chrUn" | grep -v "chrEBV" | grep -v "chrM" | \
    intersectBed -v -a stdin -b $blacklist > ${factor}_tmp.txt
  mv ${factor}_tmp.txt ${main}/macs2/${factor}_peaks.narrowPeak 
  grep -v "random" ${main}/macs2/${factor}_summits.bed | grep -v "chrUn" | grep -v "chrEBV" | grep -v "chrM" | \
    intersectBed -v -a stdin -b $blacklist > ${factor}_tmp.txt
  mv ${factor}_tmp.txt ${main}/macs2/${factor}_summits.bed 
done
```

## Count reads in peaks

Count reads that overlap any part of the full narrowPeak region.

```{r engine='bash', eval=F, echo=TRUE}
cd ${main}/counts/
for bed in `ls *_not_scaled.bed | grep -v IgG`
do
  name=`basename $bed _not_scaled.bed`
  factor=$(echo $name | awk -F"_" '{print $3}')
  sbatch -p standard -A gioeli_lab -t 10:00 -N 1 -n 1 --job-name ${name}_mapBed \
    -o /scratch/ts2hx/${title}/logs/${name}_mapBed.log \
    --wrap="module load gcc/9.2.0 bedtools/2.29.2; \
      mapBed -null "0" -a ${main}/macs2/${factor}_peaks.narrowPeak -b $bed > ${name}_peak_counts.txt"
  sleep 1 # wait 1 second between each job submission
done
```

Just keep the last column (the counts). I should do this in the above jobs. 

```{r engine='bash', eval=F, echo=TRUE}
for counts in T47D_Clone28_*_peak_counts.txt
do
  name=`basename $counts _peak_counts.txt`
  awk '{print $NF}' ${name}_peak_counts.txt > ${name}_peak_counts_only.txt
  echo $name | cat - ${name}_peak_counts_only.txt > ${name}_peak_counts.txt
  rm ${name}_peak_counts_only.txt
done
```

Combine into 1 file per factor.

```{r engine='bash', eval=F, echo=TRUE}
for peaks in ../macs2/*_peaks.narrowPeak
do
  factor=`basename $peaks _peaks.narrowPeak`
  awk '{OFS = "\t"} {print $1, $2, $3}' $peaks > peaks.bed
  echo -e "chr\tstart\tend" | cat - peaks.bed > peaks_header.bed
  paste -d'\t' peaks_header.bed T47D_Clone28_${factor}_*_peak_counts.txt > Combined_${factor}_peak_counts.txt
  rm peaks*
done
```

## Call TRPS1 peaks with the dTAG samples as a control

The script used in the next code chunk (230322_macs2.sh) is below:

```{r engine='bash', eval=F, echo=TRUE}
#!/bin/bash

samples=$1
control=$2
factor=$3
main=$4

blacklist=$HOME/hg38/hg38.blacklist.bed

module load macs2/2.2.7.1 gcc/7.1.0 openmpi/3.1.4 intel/18.0 intelmpi/18.0 R/4.1.1 bedtools/2.26.0

macs2 callpeak --call-summits -t ${samples}_*.bam -c ${control}_*.bam -f BAMPE -g hs -n $factor --keep-dup all \
  --outdir ${main}/macs2 
grep -v "random" ${main}/macs2/${factor}_peaks.narrowPeak | grep -v "chrUn" | grep -v "chrEBV" | grep -v "chrM" | \
  grep -v "alt" | intersectBed -v -a stdin -b $blacklist > ${factor}_tmp.txt
mv ${factor}_tmp.txt ${main}/macs2/${factor}_peaks.narrowPeak 
grep -v "random" ${main}/macs2/${factor}_summits.bed | grep -v "chrUn" | grep -v "chrEBV" | grep -v "chrM" | \
    grep -v "alt" | intersectBed -v -a stdin -b $blacklist > ${factor}_tmp.txt
mv ${factor}_tmp.txt ${main}/macs2/${factor}_summits.bed 
slopBed -b 50 -i ${main}/macs2/${factor}_summits.bed -g $HOME/hg38/hg38.chrom.sizes > \
  ${main}/macs2/${factor}_summit_window.bed
```

Run the above script on the HA samples.

```{r engine='bash', eval=F, echo=TRUE}
cd ${main}/bowtie2/
factor=HA_DMSO_vs_dTAG
samples=T47D_Clone28_HA_DMSO
control=T47D_Clone28_HA_dTAG
sbatch -p largemem -A gioeli_lab -t 4:00:00 -N 1 -n 1 --mem-per-cpu=64000 --job-name macs2 \
  -o /scratch/ts2hx/${title}/logs/${factor}_macs2.log \
  --wrap="sh ${scripts}/230322_macs2.sh $samples $control $factor $main"
```

Count reads in HA peaks.

```{r engine='bash', eval=F, echo=TRUE}
cd ${main}/counts/
#Just count read fragments that overlap the summit
peaks=${main}/macs2/${factor}_summits.bed
for bed in T47D_Clone28_HA_*_not_scaled.bed T47D_Clone28_IgG_*_not_scaled.bed
do
  name=`basename $bed _not_scaled.bed`
  echo $name
  name=${name}_${factor}
  mapBed -null "0" -a $peaks -b $bed > ${name}_peak_counts.txt
  awk '{print $NF}' ${name}_peak_counts.txt > ${name}_peak_counts_only.txt
  echo $name | cat - ${name}_peak_counts_only.txt > ${name}_peak_counts.txt
  rm ${name}_peak_counts_only.txt
done

echo -e "chr\tstart\tend\tname\tqvalue" | cat - $peaks | \
  paste -d'\t' - *${factor}_peak_counts.txt > Combined_${factor}_peak_counts.txt
rm T47D_Clone28_*${factor}_peak_counts.txt
```

## Scale and merge bigWigs for use in the genome browser

First make size factors based on total mapped reads (divide each by the geometric mean of all of them like in DESeq2).

```{r engine='bash', eval=F, echo=TRUE}
cd ${main}/bowtie2
module load samtools/1.12
for i in HA ER
do
  echo $i
  > ${i}_header.txt
  > ${i}_reads.txt
  for j in T47D_Clone28_${i}_*.bam
  do
    echo $j
    name=$(echo $j | awk -F".bam" '{print $1}')
    echo $name | paste ${i}_header.txt - > ${i}_tmp.txt 
    mv ${i}_tmp.txt ${i}_header.txt
    reads=`samtools view -c $j`
    echo $reads | paste ${i}_reads.txt - > ${i}_tmp.txt 
    mv ${i}_tmp.txt ${i}_reads.txt
  done  
  cat ${i}_header.txt ${i}_reads.txt > ${i}_tmp.txt
  mv ${i}_tmp.txt ${i}_reads.txt
  rm ${i}_header.txt
done 
```

Combine these into one file.

```{r engine='bash', eval=F, echo=TRUE}
module load gcc/9.2.0  openmpi/3.1.6 R/4.2.1
R
library(DESeq2)
setwd("/scratch/ts2hx/ChIP/results/bowtie2/")
samples <- dir("/scratch/ts2hx/ChIP/results/bowtie2/", pattern = "_reads.txt")
for (i in samples) {
  x <- read.table(i, sep = '\t', header = TRUE)[,-1]
  factor = sapply(strsplit(colnames(x)[1], "_"), "[", 3)
  write.table(estimateSizeFactorsForMatrix(x), file = paste0("/scratch/ts2hx/ChIP/results/bigWigs/", factor, '_sizeFactor.txt'), quote =F, col.names=F)
}
q()
```

Generate the binned bigWigs.

```{r engine='bash', eval=F, echo=TRUE}
for i in *.bam
do
  name=$(echo $i | awk -F".bam" '{print $1}')
  sbatch -p standard -A gioeli_lab -t 1:00:00 --cpus-per-task=10 --job-name bamCoverage -o ${name}_bamCoverage.log \
    --export=ALL,name=$name,main=$main --wrap="module load deeptools/3.5.1 samtools/1.12; samtools index ${name}.bam; \
    bamCoverage --bam ${name}.bam -o ${main}/bigWigs/${name}_binned_not_scaled.bw -p 10 --extendReads --centerReads;"
  sleep 1
done
```

The script used in the next code chunk (230329_ChIP_scale_bigWig_binned.sh) is below. It scales each bigWig based on the read depth.

```{r engine='bash', eval=F, echo=TRUE}
#! /bin/bash
factor=$2
directory=$3

PATH=$HOME/bin:$PATH

cd $directory

module load ucsc-tools/3.7.4

name=$(echo $1 | awk -F"_binned_not_scaled.bw" '{print $1}')
invscale1=$(grep ${name} ${factor}_sizeFactor.txt | awk -F" " '{print $2}')
invscale=$(echo $invscale1 | bc)
scaletrue=$(bc <<< "scale=4 ; 1.0 / $invscale")
name=${name}_binned
echo $name
echo $scaletrue
echo file_to_scale
echo ${name}_not_scaled.bw
bigWigToBedGraph ${name}_not_scaled.bw ${name}.bg
echo normalizing
normalize_bedGraph.py -i ${name}.bg -s $scaletrue -o ${name}_scaled.bg
LC_COLLATE=C sort -k1,1 -k2,2n ${name}_scaled.bg > ${name}_scaled_sorted.bg
cat ${name}_scaled_sorted.bg | grep -v "random" | grep -v "chrUn" | grep -v "chrEBV" | grep -v "chrM"> \
  ${name}_scaled.bg
bedGraphToBigWig ${name}_scaled.bg $HOME/hg38/hg38.chrom.sizes ${name}_scaled.bigWig
rm ${name}_scaled.bg
rm ${name}_scaled_sorted.bg
rm ${name}.bg
```

Run the above script on each sample in parallel.

```{r engine='bash', eval=F, echo=TRUE}
cd ${main}/bigWigs
for i in *_binned_not_scaled.bw
do
  name=$(echo $i | awk -F"_binned_not_scaled.bw" '{print $1}')
  factor=$(echo $name | awk -F"_" '{print $3}')
  sbatch -p standard -A gioeli_lab -t 1:00:00 --cpus-per-task=10 --job-name scale_bigWig \
    -o ../../logs/${name}_bamCoverage.log --wrap="sh ${scripts}/230329_ChIP_scale_bigWig_binned.sh \
      ${name}_binned_not_scaled.bw $factor ${main}/bigWigs"
  sleep 1
done
```

The script used in the next code chunk (230329_ChIP_to_browser_binned.sh) is below. It merges the scaled bigWigs across replicates into one bigWig and one bedGraph per condition. 

```{r engine='bash', eval=F, echo=TRUE}
#! /bin/bash
directory=$2

PATH=$HOME/bin:$PATH

cd $directory

module load ucsc-tools/3.7.4

name=$(echo $1 | awk -F"T47D_Clone28_" '{print $2}' | awk -F"_rep1" '{print $1}')
echo $name
files=$(ls T47D_Clone28_${name}_rep*_binned_scaled.bigWig)
echo $files
echo "track type=bedGraph name=${name} alwaysZero=on visibility=full" > T47D_Clone28_${name}_binned_temp.txt
count=$(ls T47D_Clone28_${name}_rep*_binned_scaled.bigWig | wc -l | bc)
scaleall=$(bc <<< "scale=4 ; 1.0 / $count")
name=T47D_Clone28_${name}_binned
echo $count
echo $scaleall
bigWigMerge $files ${name}_tmp.bg
normalize_bedGraph.py -i ${name}_tmp.bg -s $scaleall -o ${name}_scaled.bg
LC_COLLATE=C sort -k1,1 -k2,2n ${name}_scaled.bg > ${name}_scaled_sorted.bg
cat ${name}_temp.txt ${name}_scaled_sorted.bg | \
  grep -v "random" | grep -v "chrUn" | grep -v "chrEBV" | grep -v "chrM" | grep -v "alt" > \
  ${name}_scaled.bedGraph
rm ${name}_tmp.bg
rm ${name}_temp.txt
rm ${name}_scaled.bg
rm ${name}_scaled_sorted.bg
head ${name}_scaled.bedGraph
bedGraphToBigWig ${name}_scaled.bedGraph $HOME/hg38/hg38.chrom.sizes \
  ${name}_combined_normalized.bigWig
gzip ${name}_scaled.bedGraph
```

Run the above script on each condition in parallel.

```{r engine='bash', eval=F, echo=TRUE}
for i in T47D_Clone28_*_rep1_binned_scaled.bigWig
do
  name=$(echo $i | awk -F"_rep1_scaled.bigWig" '{print $1}')
  sbatch -p largemem -A gioeli_lab -t 4:00:00 -N 1 -n 1 --job-name to_browser -o ../../logs/${name}_to_browser.log \
  --wrap="sh ${scripts}/230329_ChIP_to_browser_binned.sh $i ${main}/bigWigs"
  sleep 1
done
```

## Leave the cluster environment, and copy files to your local computer

```{r engine='bash', eval=F, echo=TRUE}
exit
exit

title=ChIP
main=/scratch/ts2hx/${title}/results
cd /Users/TScott/Library/CloudStorage/Box-Box/GuertinLab/${title}/results
scp -r ts2hx@rivanna.hpc.virginia.edu:${main}/fastqc/ .
scp -r ts2hx@rivanna.hpc.virginia.edu:${main}/macs2/*_summit* macs2/
scp -r ts2hx@rivanna.hpc.virginia.edu:${main}/macs2/*peaks.narrowPeak macs2/
scp -r ts2hx@rivanna.hpc.virginia.edu:${main}/counts/Combined* counts/
scp -r ts2hx@rivanna.hpc.virginia.edu:${main}/bigWigs/*_not_scaled.bw bigWigs/
scp ts2hx@rivanna.hpc.virginia.edu:/scratch/ts2hx/ChIP/results/bigWigs/*_binned_scaled.bedGraph.gz bigWigs/
scp ts2hx@rivanna.hpc.virginia.edu:/scratch/ts2hx/ChIP/results/bigWigs/*_binned_combined_normalized.bigWig bigWigs/
scp ts2hx@rivanna.hpc.virginia.edu:/scratch/ts2hx/ChIP/results/bigWigs/*_sizeFactor.txt counts/
```

# TRPS1 ChIP-seq analysis

## Heatmap of TRPS1 peak intensity in dTAG vs. DMSO (Figure 2C)

Set up.

```{r engine='bash', eval=F, echo=TRUE}
ssh -Y ts2hx@rivanna.hpc.virginia.edu 
ijob -c 1 -A gioeli_lab -p standard --cpus-per-task=20 --time=12:00:00
main=/scratch/ts2hx/ChIP/results
cd $main
mkdir -p heatmaps
cd heatmaps

module load deeptools/3.5.1
```

Define functional TRPS1 peaks by MACS2 q-value < 10^(-30). I chose this based on making CDFs for TRPS1 proximity to activated genes using the PRO-seq data. More liberal q-values gave peaks that were promoter-proximal and not differentially close to activated genes compared to unchanged genes. 

```{r engine='bash', eval=F, echo=TRUE}
awk '$5 > 30' /scratch/ts2hx/ChIP/results/macs2/HA_DMSO_vs_dTAG_summits.bed > \
  Functional_TRPS1_summits.bed
```

Make the matrix (this can be used for a composite profile as well).

```{r engine='bash', eval=F, echo=TRUE}
computeMatrix reference-point --referencePoint center -b 500 -a 500 -p 20 --missingDataAsZero \
  -R Functional_TRPS1_summits.bed \
  -S /scratch/ts2hx/ChIP/results/bigWigs/T47D_Clone28_HA_DMSO_combined_normalized.bigWig \
  /scratch/ts2hx/ChIP/results/bigWigs/T47D_Clone28_HA_dTAG_combined_normalized.bigWig \
  -o matrix_HA_ChIP_TRPS1_peaks.gz --outFileSortedRegions TRPS1_peaks_sorted_for_heatmap.bed
```

Make the heatmap.

```{r engine='bash', eval=F, echo=TRUE}
plotHeatmap -m matrix_HA_ChIP_TRPS1_peaks.gz -out heatmap_HA_ChIP_TRPS1_peaks.pdf --heatmapHeight 14 \
   --regionsLabel "Functional TRPS1 peaks" --xAxisLabel "Distance from summit" \
   --samplesLabel "DMSO" "dTAG" --colorMap Purples --whatToShow "heatmap and colorbar" 
```

Leave the cluster environment, and copy files to your local computer.

```{r engine='bash', eval=F, echo=TRUE}
exit
exit

cd ~/Library/CloudStorage/Box-Box/GuertinLab/ChIP/results
scp -r ts2hx@rivanna.hpc.virginia.edu:/scratch/ts2hx/ChIP/results/heatmaps .
```

## MA plot of TRPS1 peak intensity in dTAG vs. DMSO (Figure 2D)

First get the complexity estimate file for size factors (total aligned reads).

```{r engine='bash', eval=F, echo=TRUE}
title=ChIP
cd /Users/TScott/Library/CloudStorage/Box-Box/GuertinLab/${title}/
scp -r ts2hx@rivanna.hpc.virginia.edu:/scratch/ts2hx/${title}/logs/*chipseq.log logs/
scp -r ts2hx@rivanna.hpc.virginia.edu:/scratch/ts2hx/${title}/results/chipqc/chipObj.R results/chipqc/

cd logs
echo -e "name\traw_reads\taligned_reads\tunique_reads\testimated_size\tresultant_reads" > \
  230322_complexity_estimate.txt
for i in *_HA_*_chipseq.log *_ER_*_chipseq.log *_IgG_*_chipseq.log
do
  name=`basename $i _chipseq.log`
  raw_reads=`grep "Raw reads:" $i | awk '{print $3}'`
  aligned_reads=`grep "READ:" $i | awk '{print $2/2}'`
  unique_reads=`grep "WRITTEN:" $i | awk '{print $2/2}'`
  estimated_size=`grep "ESTIMATED_LIBRARY_SIZE:" $i | awk '{print $2}'`
  resultant_reads=`grep "Resultant reads:" $i | awk '{print $3}'`
  echo -e "$name\t$raw_reads\t$aligned_reads\t$unique_reads\t$estimated_size\t$resultant_reads" >> \
    230322_complexity_estimate.txt
done
```

Now use DESeq2 to identify differentially bound peaks (in this case all of them).

```{r class.source="bg-info", engine='R', eval=F, echo=T}
direc = '~/Library/CloudStorage/Box-Box/GuertinLab/ChIP/results/counts/'
setwd(direc)

library(DESeq2)
library(lattice)
library(viridis)
library(DEGreport)
library(lattice)
library(dplyr)
library(tidyr)
library(ggplot2)
library(data.table)
```

Get read depth.

```{r class.source="bg-info", engine='R', eval=F, echo=T}
complexity_estimate <- read.table("~/Library/CloudStorage/Box-Box/GuertinLab/ChIP/logs/230322_complexity_estimate.txt", header = T)
name = sapply(strsplit(complexity_estimate$name, "Clone28_"), "[", 2)
complexity_estimate = t(complexity_estimate$unique_reads)
colnames(complexity_estimate) = name
complexity_estimate = complexity_estimate[,-grep("ER", colnames(complexity_estimate))]
```

Read in the counts table and change the column names.

```{r class.source="bg-info", engine='R', eval=F, echo=T}
x <- read.table("Combined_HA_DMSO_vs_dTAG_peak_counts.txt", sep = '\t', header = TRUE)
rownames(x) = paste0(x[,1], ":", x[,2], "-", x[,3])
peak_name = x[,4]
peak_qvalue = x[,5]
x = x[,-c(1:6)]
colnames(x) = sapply(strsplit(sapply(strsplit(colnames(x), "Clone28_"), "[", 2), "_HA_DMSO"), "[", 1)
```

Subtract the read depth normalized background signal.

```{r class.source="bg-info", engine='R', eval=F, echo=T}
background <- sweep(x[,grep("IgG", colnames(x))], 2, complexity_estimate[grep("IgG", names(complexity_estimate))], FUN = "/")
background = rowMeans(background)
background = cbind.data.frame(background, background, background, background, background, background, background, background)
background <- sweep(as.data.frame(background), 2, complexity_estimate[grep("HA", names(complexity_estimate))], FUN = "*")
background = round(background, digits = 0)

x = x[,grep("HA", colnames(x))] - background
x[x < 0] = 0
```

Run Deseq2.

```{r class.source="bg-info", engine='R', eval=F, echo=T}
treatment = factor(sapply(strsplit(colnames(x), '_'), '[', 2), levels = c("DMSO", "dTAG"))
rep = factor(sapply(strsplit(colnames(x), 'rep'), '[', 2))
deseq.df = DESeqDataSetFromMatrix(x, cbind.data.frame(treatment, rep), ~ treatment)
factors <- read.table("HA_sizeFactor.txt")
size_factors = factors$V2
names(size_factors) = factors$V1
sizeFactors(deseq.df) <- size_factors
deseq.df = DESeq(deseq.df)
```

Plot.

```{r class.source="bg-info", engine='R', eval=F, echo=T}
pdf("MA_HA_DMSO_vs_dTAG_subtract_IgG_qvalue_30.pdf")
res.deseq = results(deseq.df[peak_qvalue > 30,], contrast = c("treatment", "dTAG", "DMSO"))
save(res.deseq, file = "res.deseq.HA.q30.Rdata")
plotMA(res.deseq, ylim = c(-4,4))
dev.off()
```

# ATAC-seq data pre-processing

## Set up

Log in to the cluster to perform the processing for each sample in parallel.

```{r engine='bash', eval=F, echo=TRUE}
ssh -Y ts2hx@rivanna.hpc.virginia.edu 
ijob -c 1 -A gioeli_lab -p standard --cpus-per-task=10 --time=8:00:00
```

Make the main directory (should make nice subdirectories like I did for ChIP).

```{r engine='bash', eval=F, echo=TRUE}
main=/scratch/ts2hx/TRPS1_timecourse_ATAC
mkdir -p $main
```

Get the required script for bigWig merging and move to a directory that will end up in the $PATH.

```{r engine='bash', eval=F, echo=TRUE}
wget https://raw.githubusercontent.com/guertinlab/Nascent_RNA_Methods/main/normalize_bedGraph.py
chmod +x normalize_bedGraph.py
mv normalize_bedGraph.py $HOME/bin/
```

Get the ENCODE blacklist.

```{r engine='bash', eval=F, echo=TRUE}
wget https://raw.githubusercontent.com/Boyle-Lab/Blacklist/master/lists/hg38-blacklist.v2.bed.gz -P $HOME/hg38/
gunzip $HOME/hg38/hg38-blacklist.v2.bed.gz
mv $HOME/hg38/hg38-blacklist.v2.bed $HOME/hg38/hg38.blacklist.bed
```

Get chrM for pre-alignment.

```{r engine='bash', eval=F, echo=TRUE}
module load gcc/9.2.0 bowtie2/2.2.9 
wget https://hgdownload.soe.ucsc.edu/goldenPath/hg38/bigZips/hg38.chromFa.tar.gz
tar -xzf hg38.chromFa.tar.gz
mkdir -p $HOME/hg38
mv chroms/chrM.fa $HOME/hg38
rm -r chroms
rm hg38.chromFa.tar.gz
ls $HOME/hg38
bowtie2-build $HOME/hg38/chrM.fa $HOME/hg38/chrM_hg38
```

Make tallymer and table for seqOutBias (this takes a while).

```{r engine='bash', eval=F, echo=TRUE}
cd $HOME/seqOutBias/
seqOutBias seqtable /project/genomes/Homo_sapiens/UCSC/hg38/Sequence/Bowtie2Index/genome.fa --read-size=62
```

## Download the raw data and rename the files

Once these files are public on SRA, we can update the SRR numbers.

```{r engine='bash', eval=F, echo=TRUE}
cd $main
fasterq-dump SRRTBD
```

This may be unnecessary if the SRA downloads are already named appropriately. 

```{r engine='bash', eval=F, echo=TRUE}
for i in *_R1_001.fastq.gz
do
name=$(echo $i | awk -F"_S[0-9]" '{print $1}')
echo $name
hyphenless=${name//-/_}
echo $hyphenless
newname=${hyphenless//05hour/0.5hour}
echo $newname
mv ${name}_*_R1_001.fastq.gz ${newname}_PE1.fastq.gz
mv ${name}_*_R2_001.fastq.gz ${newname}_PE2.fastq.gz
done
```

## Process each sample

The script used in the next code chunk (230417_ATACseq_analysis_on_input_file.sh) is below:

```{r engine='bash', eval=F, echo=TRUE}
#! /bin/bash
directory=/scratch/$USER/TRPS1_timecourse_ATAC
read_size=62
cores=$SLURM_CPUS_PER_TASK
chrM=$HOME/hg38/chrM_hg38
genome_index=/project/genomes/Homo_sapiens/UCSC/hg38/Sequence/Bowtie2Index/genome
tallymer=$HOME/seqOutBias/genome.tal_${read_size}.gtTxt.gz
table=$HOME/seqOutBias/genome_${read_size}.4.2.2.tbl

PATH=$HOME/bin:$PATH

cd $directory

module load cutadapt/3.4
module load gcc/9.2.0 pigz/2.4
module load bowtie2/2.2.9 
module load samtools/1.12
module load wigtobigwig/2.8
module load bedtools/2.29.2
module load deeptools/3.5.1

filename=$1
name=$(echo $filename | awk -F"_PE1.fastq.gz" '{print $1}')
echo $name
gunzip ${name}_PE1.fastq.gz
gunzip ${name}_PE2.fastq.gz
#Remove adapters (also trim PE1 reads to the same length as PE2 (that was unnecessary))
cutadapt -j $cores -l $read_size -m 10 -O 1 -a CTGTCTCTTATACACATCT ${name}_PE1.fastq -o ${name}_PE1_no_adapt.fastq
cutadapt -j $cores -m 10 -O 1 -a CTGTCTCTTATACACATCT ${name}_PE2.fastq -o ${name}_PE2_no_adapt.fastq
#Align to chrM first and remove aligned reads    
bowtie2 -p $((cores-2)) -x $chrM -U ${name}_PE1_no_adapt.fastq | \
    samtools sort -n - | samtools fastq -f 0x4 - > ${name}_PE1.chrM.fastq
#Pair reads
reads=$(wc -l ${name}_PE1.chrM.fastq | awk '{print $1/4}')
fastq_pair -t $reads ${name}_PE1.chrM.fastq ${name}_PE2_no_adapt.fastq
#Align to the hg38 genome and remove duplicates
bowtie2 -p $((cores-5)) --maxins 800 -x $genome_index \
  -1 ${name}_PE1.chrM.fastq.paired.fq -2 ${name}_PE2_no_adapt.fastq.paired.fq | \
  samtools view -bS - | samtools sort -n - | samtools fixmate -m - - | samtools sort - | \
  samtools markdup -s -r - ${name}.hg38.bam
#Convert BAM to bed for counting (previously created the tallymer with `seqOutBias seqtable`)
seqOutBias scale $table ${name}.hg38.bam --no-scale --shift-counts --skip-bw \
  --read-size=$read_size --tallymer=$tallymer --bed=$name.bed
#Remove noncanonical chromosomes and sort for use with mapBed
grep -v "random" ${name}_not_scaled.bed | grep -v "chrUn" | grep -v "chrEBV" | grep -v "alt" | \
  sort -k1,1 -k2,2n > ${name}_tmp.txt && mv ${name}_tmp.txt ${name}_not_scaled.bed 
#Convert BAM to bigWig for visualization; extends the reads from PE1 to PE2; 
#uses a bin size of 10 for a smoother output; normalizes as bins per million, analagous to TPM for transcripts
bamCoverage --bam ${name}.hg38.bam -bs 10 -p 10 -e --normalizeUsing BPM -bl $HOME/hg38/hg38.blacklist.bed \
  -o ${name}_scaled.bigWig 
#Zip fastq's and delete intermediate files
pigz -p $cores ${name}_PE1.fastq
pigz -p $cores ${name}_PE2.fastq
rm ${name}_PE1_no_adapt.fastq
rm ${name}_PE2_no_adapt.fastq
rm ${name}_PE1.chrM.fastq
rm ${name}_PE1.chrM.fastq.paired.fq
rm ${name}_PE1.chrM.fastq.single.fq
rm ${name}_PE2_no_adapt.fastq.paired.fq
rm ${name}_PE2_no_adapt.fastq.single.fq
```

Run the above script on each sample in parallel.

```{r engine='bash', eval=F, echo=TRUE}
chmod +x /scratch/ts2hx/scripts/230417_*.sh
for filename in *_PE1.fastq.gz
do
name=`basename $filename _PE1.fastq.gz`
sbatch -p standard -A gioeli_lab -t 1-00:00:00 -N 1 -n 1 --cpus-per-task=10 --job-name ${name}_atacseq_analysis \
  -o ${name}_atacseq.log  --wrap="sh /scratch/ts2hx/scripts/230417_ATACseq_analysis_on_input_file.sh $filename"
sleep 1	# wait 1 second between each job submission
done
```

## Call peaks 

This code uses all bam files, calls sub-peak summits, and makes each fragment 200bp centered on the original 5' end of the read.

```{r engine='bash', eval=F, echo=TRUE}
name=TRPS1_timecourse_ATAC
sbatch -p largemem -A gioeli_lab -t 1-00:00:00 -N 1 -n 1 --mem-per-cpu=64000 --job-name macs2 -o ${name}_macs2.log \
  --wrap="module load macs2/2.2.7.1; \
    macs2 callpeak --call-summits -t *.hg38.bam -n TRPS1_timecourse_ATAC -g hs -q 0.01 --keep-dup all \
    -f BAM --nomodel --shift -100 --extsize 200"
```

Remove noncanonical chromosomes and blacklisted regions.

```{r engine='bash', eval=F, echo=TRUE}
blacklist=$HOME/hg38/hg38.blacklist.bed
module load gcc/9.2.0 bedtools/2.29.2
grep -v "random" ${name}_peaks.narrowPeak | grep -v "chrUn" | grep -v "chrEBV" | grep -v "chrM" | \
  grep -v "alt" | intersectBed -v -a stdin -b $blacklist > ${name}_tmp.txt
mv ${name}_tmp.txt ${name}_peaks.narrowPeak 
grep -v "random" ${name}_summits.bed | grep -v "chrUn" | grep -v "chrEBV" | grep -v "chrM" | \
    grep -v "alt" | intersectBed -v -a stdin -b $blacklist > ${name}_tmp.txt
mv ${name}_tmp.txt ${name}_summits.bed 
```

Make a window of 100bp on either side of the summit.

```{r engine='bash', eval=F, echo=TRUE}
slopBed -b 100 -i ${name}_summits.bed -g $HOME/hg38/hg38.chrom.sizes > ${name}_summit_window.bed
```

## Count reads in peaks

Count reads where the cut site is within these windows.

```{r engine='bash', eval=F, echo=TRUE}
peaks=${name}_summit_window.bed
for bed in *_not_scaled.bed
do
  name=`basename $bed _not_scaled.bed`
  sbatch -p standard -A gioeli_lab -t 1:00:00 -N 1 -n 1 --job-name ${name}_mapBed -o ${name}_mapBed.log \
    --wrap="module load gcc/9.2.0 bedtools/2.29.2; mapBed -null '0' -a $peaks -b $bed > ${name}_peak_counts.txt;"
  sleep 1
done
```

Just keep the last column (the counts). I should do this in the above jobs.

```{r engine='bash', eval=F, echo=TRUE}
for counts in T47D_Clone28_*_peak_counts.txt
do
  name=`basename $counts _peak_counts.txt`
  awk '{print $NF}' ${name}_peak_counts.txt > ${name}_peak_counts_only.txt
  echo $name | cat - ${name}_peak_counts_only.txt > ${name}_peak_counts.txt
  rm ${name}_peak_counts_only.txt
done
```

Combine into 1 file per factor.

```{r engine='bash', eval=F, echo=TRUE}
echo -e "chr\tstart\tend\tname\tqvalue" | cat - $peaks | \
  paste -d'\t' - T47D_Clone28_*_peak_counts.txt > Combined_ATAC_peak_counts.txt
rm T47D_Clone28_*_peak_counts.txt
```

## Make size factors for DESeq2 based on total mapped reads 

Divide each by the geometric mean of all of them.

```{r engine='bash', eval=F, echo=TRUE}
module load samtools/1.12
i=ATAC
> ${i}_header.txt
> ${i}_reads.txt
for j in T47D_Clone28_*.hg38.bam
do
  echo $j
  name=$(echo $j | awk -F".hg38.bam" '{print $1}')
  echo $name | paste ${i}_header.txt - > ${i}_tmp.txt 
  mv ${i}_tmp.txt ${i}_header.txt
  reads=`samtools view -c $j`
  echo $reads | paste ${i}_reads.txt - > ${i}_tmp.txt 
  mv ${i}_tmp.txt ${i}_reads.txt
done  
cat ${i}_header.txt ${i}_reads.txt > ${i}_tmp.txt
mv ${i}_tmp.txt ${i}_reads.txt
rm ${i}_header.txt
```

Combine these into one file.

```{r engine='bash', eval=F, echo=TRUE}
module load gcc/9.2.0  openmpi/3.1.6 R/4.2.1
R
library(DESeq2)
setwd("/scratch/ts2hx/TRPS1_timecourse_ATAC/")
samples <- "ATAC_reads.txt"
x <- read.table(samples, sep = '\t', header = TRUE)[,-1]
write.table(estimateSizeFactorsForMatrix(x), file = paste0("/scratch/ts2hx/TRPS1_timecourse_ATAC/ATAC_sizeFactor.txt"), quote =F, col.names=F)
q()
```

## Merge scaled bigWigs for use in the genome browser

The script used in the next code chunk (230417_ATAC_to_browser.sh) is below. It merges the scaled bigWigs across replicates into one bigWig and one bedGraph per condition.

```{r engine='bash', eval=F, echo=TRUE}
#! /bin/bash
directory=/scratch/$USER/TRPS1_timecourse_ATAC

PATH=$HOME/bin:$PATH

cd $directory

module load ucsc-tools/3.7.4

name=$(echo $1 | awk -F"T47D_Clone28_" '{print $2}' | awk -F"_rep1" '{print $1}')
echo $name
files=$(ls T47D_Clone28_${name}_rep*_scaled.bigWig)
echo $files
touch T47D_Clone28_${name}_temp.txt
echo "track type=bedGraph name=${name} alwaysZero=on visibility=full" >> T47D_Clone28_${name}_temp.txt
count=$(ls T47D_Clone28_${name}_rep*_scaled.bigWig | wc -l | bc)
scaleall=$(bc <<< "scale=4 ; 1.0 / $count")
name=T47D_Clone28_${name}
echo $count
echo $scaleall
bigWigMerge $files ${name}_tmp.bg
normalize_bedGraph.py -i ${name}_tmp.bg -s $scaleall -o ${name}_scaled.bg
LC_COLLATE=C sort -k1,1 -k2,2n ${name}_scaled.bg > ${name}_scaled_sorted.bg
cat ${name}_temp.txt ${name}_scaled_sorted.bg > ${name}_scaled.bedGraph
rm ${name}_tmp.bg
rm ${name}_temp.txt
rm ${name}_scaled.bg
rm ${name}_scaled_sorted.bg
head ${name}_scaled.bedGraph
bedGraphToBigWig ${name}_scaled.bedGraph hg38.chrom.sizes ${name}_combined_normalized.bigWig
gzip -f ${name}_scaled.bedGraph
```

Run the above script on each sample in parallel.

```{r engine='bash', eval=F, echo=TRUE}
for i in T47D_Clone28_*_rep1_scaled.bigWig
do
  name=$(echo $i | awk -F"_rep1_scaled.bigWig" '{print $1}')
  sbatch -p largemem -A gioeli_lab -t 4:00:00 -N 1 -n 1 --job-name to_browser -o ${name}_to_browser.log \
  --wrap="sh /scratch/ts2hx/scripts/230417_ATAC_to_browser.sh $i"
  sleep 1
done
```

## Leave the cluster environment, and copy files to your local computer

```{r engine='bash', eval=F, echo=TRUE}
exit
exit

#Copy files
cd ~/Library/CloudStorage/Box-Box/GuertinLab/TRPS1_timecourse_ATAC
scp ts2hx@rivanna.hpc.virginia.edu:/scratch/ts2hx/TRPS1_timecourse_ATAC/Combined_ATAC_peak_counts.txt .
scp ts2hx@rivanna.hpc.virginia.edu:/scratch/ts2hx/TRPS1_timecourse_ATAC/ATAC_sizeFactor.txt .
```

# ATAC-seq analysis

## MA plot of chromatin accessibility at 30 minutes dTAG vs. DMSO (Figure 3A)

Set up libraries and functions in R.

```{r class.source="bg-info", engine='R', eval=F, echo=T}
direc = '~/Library/CloudStorage/Box-Box/GuertinLab/TRPS1_timecourse_ATAC/'
setwd(direc)

library(DESeq2)
library(lattice)
library(viridis)
library(DEGreport)
library(lattice)
library(dplyr)
library(tidyr)
library(ggplot2)
library(data.table)
library(MatchIt)

tighten_summit_window <- function(res.deseq, b = 100) {
  chr = sapply(strsplit(rownames(res.deseq), ':'), '[', 1)
  start = as.numeric(sapply(strsplit(sapply(strsplit(rownames(res.deseq), ':'), '[', 2), "-"), "[", 1)) + b
  end = as.numeric(sapply(strsplit(rownames(res.deseq), '-'), '[', 2)) - b
  df = cbind.data.frame(chr, start, end)
  return(df)
}

`%notin%` <- Negate(`%in%`)
```

Read in the counts table and change the column names.

```{r class.source="bg-info", engine='R', eval=F, echo=T}
x <- read.table("Combined_ATAC_peak_counts.txt", sep = '\t', header = TRUE)
rownames(x) = paste0(x[,1], ":", x[,2], "-", x[,3])
peak_name = x[,4]
peak_qvalue = x[,5]
x = x[,-c(1:5)]
colnames(x) = sapply(strsplit(colnames(x), "Clone28_"), "[", 2)
```

Run DESeq2.

```{r class.source="bg-info", engine='R', eval=F, echo=T}
time = factor(sapply(strsplit(colnames(x), '_'), '[', 1), levels = c("0hour", "0.5hour", "1hour", "2hour", "4hour", "24hour"))
rep = factor(sapply(strsplit(colnames(x), 'rep'), '[', 2))
deseq.df = DESeqDataSetFromMatrix(x, cbind.data.frame(time, rep), ~ rep + time)
factors <- read.table("ATAC_sizeFactor.txt")
size_factors = factors$V2
names(size_factors) = factors$V1
sizeFactors(deseq.df) <- size_factors
deseq.df = DESeq(deseq.df)
save(deseq.df, file = "deseq.df.ATAC.Rdata")
load("deseq.df.ATAC.Rdata")
```

Identify differentially accessible peaks.

```{r class.source="bg-info", engine='R', eval=F, echo=T}
i = "0.5hour"
res.deseq = results(deseq.df[peak_qvalue > 100,], contrast = c("time", i, "0hour"))
sum(res.deseq$padj < 0.1 & !is.na(res.deseq$padj))
```

Match the unchanged peaks to activated peaks based on accessibility.

```{r class.source="bg-info", engine='R', eval=F, echo=T}
activated = res.deseq[res.deseq$padj < 0.1 & !is.na(res.deseq$padj) & res.deseq$log2FoldChange > 0,]
unchanged = res.deseq[!is.na(res.deseq$padj) & res.deseq$padj > 0.1 & abs(res.deseq$log2FoldChange) < 0.01,]
unchanged$treatment = 0
activated$treatment = 1
df.deseq.effects.lattice = rbind(unchanged, activated)
out = matchit(treatment ~ baseMean, data = df.deseq.effects.lattice, method = "optimal", ratio = 1)
unchanged = df.deseq.effects.lattice[rownames(df.deseq.effects.lattice) %in% out$match.matrix,]
repressed = res.deseq[res.deseq$padj < 0.1 & !is.na(res.deseq$padj) & res.deseq$log2FoldChange < 0,]

df.deseq.effects.lattice = res.deseq
df.deseq.effects.lattice$status = "Other"
df.deseq.effects.lattice$status[rownames(df.deseq.effects.lattice) %in% rownames(activated)] = "Increased"
df.deseq.effects.lattice$status[rownames(df.deseq.effects.lattice) %in% rownames(unchanged)] = "Unchanged"
df.deseq.effects.lattice$status[rownames(df.deseq.effects.lattice) %in% rownames(repressed)] = "Decreased"
df.deseq.effects.lattice$status = factor(df.deseq.effects.lattice$status, levels = c("Other", "Increased", "Unchanged", "Decreased"))
```

Plot.

```{r class.source="bg-info", engine='R', eval=F, echo=T}
pdf(paste0("MA_ATAC_q100_", i, "_for_figure.pdf"), width = 7, height = 3.5)
ggplot(as.data.frame(df.deseq.effects.lattice) %>% arrange(status), aes(x = log(baseMean, 10), y = log2FoldChange, color = status)) +
  geom_point() +
  scale_color_manual(values = c("grey90", "red", "grey60", "blue")) +
  geom_hline(yintercept = 0, linetype="dashed") +
  ylim(-1.2, 1.2) +
  xlim(1.5, 3.5) +
  ylab(expression("log"[2]~"(fold change in ATAC signal)")) +
  xlab(expression("log"[10]~"(mean of normalized intensity)")) +
  ggtitle("Change in chromatin accessibility upon TRPS1 depletion") +
  theme_bw() +
  theme(plot.title = element_text(hjust = 0.5)) +
  labs(color=NULL)
dev.off()
```

## de novo identification of enriched motifs in increased or decreased peaks using MEME (Figure 3B)

For each time point, identify differentially accessible peaks and match based on accessibility. Should have called these "increased" and "decreased" for consistency.

```{r class.source="bg-info", engine='R', eval=F, echo=T}
for (i in levels(time)[-1]) {
  res.deseq = results(deseq.df[peak_qvalue > 100,], contrast = c("time", i, "0hour"))
  sum(res.deseq$padj < 0.1 & !is.na(res.deseq$padj))
  
  activated = res.deseq[res.deseq$padj < 0.1 & !is.na(res.deseq$padj) & res.deseq$log2FoldChange > 0,]
  write.table(tighten_summit_window(activated, b = 100), file = paste0(i, '_activated_peaks.bed'), quote = FALSE, row.names = FALSE, col.names = FALSE, sep = '\t')
  
  unchanged = res.deseq[!is.na(res.deseq$padj) & res.deseq$padj > 0.1 & abs(res.deseq$log2FoldChange) < 0.01,]
  unchanged$treatment = 0
  activated$treatment = 1
  df.deseq.effects.lattice = rbind(unchanged, activated)
  out = matchit(treatment ~ baseMean, data = df.deseq.effects.lattice, method = "optimal", ratio = 1)
  unchanged = df.deseq.effects.lattice[rownames(df.deseq.effects.lattice) %in% out$match.matrix,]
  write.table(tighten_summit_window(unchanged, b = 100), file = paste0(i, '_activated_matched_peaks.bed'), quote = FALSE, row.names = FALSE, col.names = FALSE, sep = '\t')
  
  repressed = res.deseq[res.deseq$padj < 0.1 & !is.na(res.deseq$padj) & res.deseq$log2FoldChange < 0,]
  write.table(tighten_summit_window(repressed, b = 100), file = paste0(i, '_repressed_peaks.bed'), quote = FALSE, row.names = FALSE, col.names = FALSE, sep = '\t')
  
  unchanged = res.deseq[rownames(res.deseq) %notin% rownames(repressed) & !is.na(res.deseq$padj) & res.deseq$log2FoldChange > 0,]
  unchanged$treatment = 0
  repressed$treatment = 1
  df.deseq.effects.lattice = rbind(unchanged, repressed)
  out = matchit(treatment ~ baseMean, data = df.deseq.effects.lattice, method = "optimal", ratio = 1)
  unchanged = df.deseq.effects.lattice[rownames(df.deseq.effects.lattice) %in% out$match.matrix,]
  write.table(tighten_summit_window(unchanged, b = 100), file = paste0(i, '_repressed_matched_peaks.bed'), quote = FALSE, row.names = FALSE, col.names = FALSE, sep = '\t')
}
```

For each time point, run MEME on the increased and decreased peaks.

```{r engine='bash', eval=F, echo=TRUE}
cd ~/Library/CloudStorage/Box-Box/GuertinLab/TRPS1_timecourse_ATAC
genome=~/Library/CloudStorage/Box-Box/GuertinLab/hg38/hg38.fa

for bed in *_activated_peaks.bed *_repressed_peaks.bed
do
  name=`basename $bed .bed`
  fastaFromBed -fi $genome -bed ${name}.bed -fo ${name}.fasta
  sites=`wc -l ${name}.fasta | awk '{print $1/2}'`
  if [ $sites -lt 100 ] 
  then
    minsites=2
  else
    minsites=`echo $sites | awk '{print $1/50}'`
  fi
  meme -oc ${name}_meme_output -nmotifs 1000 -objfun classic -csites 20000 -evt 0.01 \
    -searchsize 0 -minw 6 -maxw 18 -revcomp -dna -markov_order 3 -maxsize 100000000 -minsites $minsites \
    ${name}.fasta
  meme -oc ${name}_meme_short_output -nmotifs 1000 -objfun classic -csites 20000 -evt 0.01 \
    -searchsize 0 -minw 6 -maxw 8 -revcomp -dna -markov_order 3 -maxsize 100000000 -minsites $minsites \
    ${name}.fasta
done
```

## Identify differentially enriched motifs in increased or decreased peaks relative to unchanged peaks using AME (Tables S1 and S2)

Report results at FDR 0.1 (1401 total in the above database).

```{r engine='bash', eval=F, echo=TRUE}
cd ~/Library/CloudStorage/Box-Box/GuertinLab/TRPS1_timecourse_ATAC/
motifs=~/Library/CloudStorage/Box-Box/GuertinLab/Motif_databases/tomtom_db/homer_uniprobe_jaspar_edited.txt
n_motifs=140
```

Make fasta files for each bed file.

```{r engine='bash', eval=F, echo=TRUE}
genome=~/Library/CloudStorage/Box-Box/GuertinLab/hg38/hg38.fa
for bed in *hour_activated*_peaks.bed *hour_repressed*_peaks.bed
do
  name=`basename $bed .bed`
  echo $name
  fastaFromBed -fi $genome -bed ${name}.bed -fo ${name}.fasta
done
```

Run AME.

```{r engine='bash', eval=F, echo=TRUE}
for fasta in *hour_activated_peaks.fasta *hour_repressed_peaks.fasta
do
  name=`basename $fasta _peaks.fasta`
  echo $name
  ame --verbose 1 --oc ${name}_ame --scoring avg --method fisher --hit-lo-fraction 0.25 \
    --evalue-report-threshold $n_motifs --control ${name}_matched_peaks.fasta ${name}_peaks.fasta $motifs
done
```

Configure the AME output for use in LaTex. Remove underscores, keep the columns we need, and convert to CSV.

```{r engine='bash', eval=F, echo=TRUE}
cd ~/Library/CloudStorage/Box-Box/guertinlab/TRPS1_timecourse_ATAC/0.5hour_repressed_ame

cat ame.tsv | \
  awk 'BEGIN {FS="\t"} {print $1, $3, $5, $15, $17, $7}' | \
  awk '{sub(/_homer.*/,"-Homer",$2)} 1' | \
  awk '{sub(/_jaspar.*/,"-Jaspar",$2)} 1' | \
  awk '{sub(/_secondary_uniprobe.*/,"-Secondary-Uniprobe",$2)} 1' | \
  awk '{sub(/_primary_uniprobe.*/,"-Secondary-Uniprobe",$2)} 1' | \
  awk '{sub(/_uniprobe.*/,"-Uniprobe",$2)} 1' | \
  awk 'BEGIN { OFS="," } {$1=$1; print}' |
  awk '/^$/{exit}1' | sed 's/%/\percent/g' > \
  decreased_ame.csv  
  
cd ~/Library/CloudStorage/Box-Box/guertinlab/TRPS1_timecourse_ATAC/0.5hour_activated_ame

cat ame.tsv | \
  awk 'BEGIN {FS="\t"} {print $1, $3, $5, $15, $17, $7}' | \
  awk '{sub(/_homer.*/,"-Homer",$2)} 1' | \
  awk '{sub(/_jaspar.*/,"-Jaspar",$2)} 1' | \
  awk '{sub(/_secondary_uniprobe.*/,"-Secondary-Uniprobe",$2)} 1' | \
  awk '{sub(/_primary_uniprobe.*/,"-Secondary-Uniprobe",$2)} 1' | \
  awk '{sub(/_uniprobe.*/,"-Uniprobe",$2)} 1' | \
  awk 'BEGIN { OFS="," } {$1=$1; print}' |
  awk '/^$/{exit}1' | sed 's/%/\percent/g' |
  head -n 50 > \
  increased_ame.csv  
```

## Count individual motif instances in dynamic peaks at 30 minutes (Figure 3C,D)

The script used in the next code chunk (220914_FIMO.sh) is below:

```{r engine='bash', eval=F, echo=TRUE}
#! /bin/bash
directory=/scratch/$USER/TRPS1_timecourse_ATAC
genome=/project/genomes/Homo_sapiens/UCSC/hg38/Sequence/Bowtie2Index/genome.fa

cd $directory
module load gcc/9.2.0 openmpi/3.1.6 meme/5.3.3 bedtools/2.29.2

fimo --thresh 0.001 --text $i $genome > ${name}_fimo.txt
wc -l ${name}_fimo.txt
score=$(tail -n +2 ${name}_fimo.txt | sort -nrk6,6 | awk 'FNR == 2000000 {print $6}')
echo $score
tail -n +2 ${name}_fimo.txt | awk -v sco="$score" '{ if ($6 >= sco) { print } }' | \
    awk '{OFS="\t";} {print $2,$3,$4,$7,$6,$5,$8}' > ${name}_2M.txt
Activated=`wc -l 24hour_activated_peaks.bed | awk '{print $1}'`
Activated_with=`intersectBed -u -a 24hour_activated_peaks.bed -b ${name}_2M.txt | wc -l | awk '{print $1}'`
Activated_without=$(echo "$Activated - $Activated_with" | bc)
Unchanged=`wc -l 24hour_unchanged_peaks.bed | awk '{print $1}'`
Unchanged_with=`intersectBed -u -a 24hour_unchanged_peaks.bed -b ${name}_2M.txt | wc -l | awk '{print $1}'`
Unchanged_without=$(echo "$Unchanged - $Unchanged_with" | bc)
Repressed=`wc -l 24hour_repressed_peaks.bed | awk '{print $1}'`
Repressed_with=`intersectBed -u -a 24hour_repressed_peaks.bed -b ${name}_2M.txt | wc -l | awk '{print $1}'`
Repressed_without=$(echo "$Repressed - $Repressed_with" | bc)
echo -e \
  "$name\t$Activated_with\t$Activated_without\t$Unchanged_with\t$Unchanged_without\t$Repressed_with\t$Repressed_without" > \
  ${name}_Motif_overlaps.txt
```

Find individual motif instances in the genome with FIMO and overlap with peak sets. I need to provide the motif files or indicate how to generate them.

```{r engine='bash', eval=F, echo=TRUE}
ssh -Y ts2hx@rivanna.hpc.virginia.edu 
ijob -c 1 -A gioeli_lab -p standard --time=1-00:00:00
cd /scratch/ts2hx/TRPS1_timecourse_ATAC/

for i in individual_memes/*_meme.txt
do
  name=`basename $i _meme.txt`
  sbatch -p standard --export=ALL,i=$i,name=$name --output=${name}_FIMO.out /scratch/ts2hx/scripts/220914_FIMO.sh
  sleep 1
done
```

Combine into one file.

```{r engine='bash', eval=F, echo=TRUE}
echo -e \
  "Motif\tActivated_with\tActivated_without\tUnchanged_with\tUnchanged_without\tRepressed_with\tRepressed_without" \
  > Motif_overlaps.txt
cat *_Motif_overlaps.txt >> Motif_overlaps.txt

exit
exit

cd ~/Library/CloudStorage/Box-Box/GuertinLab/TRPS1_timecourse_ATAC
scp ts2hx@rivanna.hpc.virginia.edu:/scratch/ts2hx/TRPS1_timecourse_ATAC/Motif_overlaps.txt .
```

Set up in R.

```{r class.source="bg-info", engine='R', eval=F, echo=T}
direc = '~/Library/CloudStorage/Box-Box/GuertinLab/TRPS1_timecourse_ATAC/'
setwd(direc)

library(tidyverse)
library(tidyr)
library(lattice)
library(tidyr)

ImmediatePeaksWithMotif <- function(motif_overlaps, motif)
{
  result = motif_overlaps[rownames(motif_overlaps) == motif,]
  result = cbind(rbind(result[,3], result[,4]), rbind(result[,1], result[,2]), rbind(result[,7], result[,8]))
  colnames(result) <- c("Increased", "Unchanged", "Decreased")
  rownames(result) <- c("With motif", "Without motif")
  print(chisq.test(result))
  #Can remove this line if you want the actual counts
  result = 100*sweep(result, 2, colSums(result), "/")
  barplot(result, col = c("#F84C1E", "#232D4B"), main = motif, legend.text = TRUE, args.legend = list(x = "topright", bg = "white", cex = 1.5), cex.axis=1.5, cex.names=1.5)
  return(result)
}
```

Plot barcharts for a representative GATA motif and ER half site.

```{r class.source="bg-info", engine='R', eval=F, echo=T}
motif_overlaps = read.table("Overlaps.txt", header = T, row.names = 1)

pdf("ATAC_GATA5_motif_heatmap_immediate.pdf")
ImmediatePeaksWithMotif(motif_overlaps, motif = "GATA5_jaspar")
dev.off()

pdf("ATAC_NR2F2_motif_heatmap_immediate.pdf")
ImmediatePeaksWithMotif(motif_overlaps, motif = "NR2F2_jaspar")
dev.off()
```

## Cluster dynamic peaks and plot the heatmap (Figure 3E)

Set up in R.

```{r class.source="bg-info", engine='R', eval=F, echo=T}
direc = '~/Library/CloudStorage/Box-Box/GuertinLab/TRPS1_timecourse_ATAC/'
setwd(direc)

library(DESeq2)
library(lattice)
library(viridis)
library(DEGreport)
library(lattice)
library(dplyr)
library(tidyr)
library(ggplot2)
library(data.table)
library(MatchIt)
library(EnhancedVolcano)
library(pheatmap)
library(dendsort)
library(RColorBrewer)

sort_hclust <- function(...) as.hclust(dendsort(as.dendrogram(...)))
```

Read in the counts table and change the column names. Here we focus on the early time points.

```{r class.source="bg-info", engine='R', eval=F, echo=T}
x <- read.table("Combined_ATAC_peak_counts.txt", sep = '\t', header = TRUE)
rownames(x) = paste0(x[,1], ":", x[,2], "-", x[,3])
peak_name = x[,4]
peak_qvalue = x[,5]
x = x[,-c(1:5)]
colnames(x) = sapply(strsplit(colnames(x), "Clone28_"), "[", 2)
x = x[,!grepl("24hour", colnames(x))]
```

Run DESeq2.

```{r class.source="bg-info", engine='R', eval=F, echo=T}
time = factor(sapply(strsplit(colnames(x), '_'), '[', 1), levels = c("0hour", "0.5hour", "1hour", "2hour", "4hour"))
rep = factor(sapply(strsplit(colnames(x), 'rep'), '[', 2))
deseq.df = DESeqDataSetFromMatrix(x, cbind.data.frame(time, rep), ~ rep + time)
factors <- read.table("ATAC_sizeFactor.txt")
size_factors = factors$V2
names(size_factors) = factors$V1
size_factors = size_factors[,!grepl("24hour", names(size_factors))]
sizeFactors(deseq.df) <- size_factors
deseq.df = DESeq(deseq.df)
save(deseq.df, file = "deseq.df.ATAC.no24.Rdata")
load("deseq.df.ATAC.no24.Rdata")
```

Run the likelihood ratio test to identify dynamic peaks over the time course.

```{r class.source="bg-info", engine='R', eval=F, echo=T}
dds.lrt = DESeq(deseq.df, test="LRT", reduced = ~ rep)
save(dds.lrt, file = "dds.lrt.ATAC.no24.Rdata")
load("dds.lrt.ATAC.no24.Rdata")
res.lrt = results(dds.lrt[peak_qvalue > 100,])
sum(res.lrt$padj < 0.1 & !is.na(res.lrt$padj))
```

Get the normalized counts.

```{r class.source="bg-info", engine='R', eval=F, echo=T}
wide_counts = counts(deseq.df[rownames(deseq.df) %in% rownames(res.lrt)[res.lrt$padj < .01 & !is.na(res.lrt$padj)],], normalized = TRUE)
```

Assign the colors.

```{r class.source="bg-info", engine='R', eval=F, echo=T}
anno <- data.frame(Time = as.factor(time))
rownames(anno) = colnames(wide_counts)
ann_colors = list(
  Time = c(`0hour` = viridis(5)[1], 
           `0.5hour` = viridis(5)[2],
           `1hour` = viridis(5)[3],
           `2hour` = viridis(5)[4],
           `4hour` = viridis(5)[5]))

paletteLength <- 50
myColor <- colorRampPalette(c("blue", "white", "red"))(paletteLength)
myBreaks <- c(seq(min(scale(t(wide_counts))), 0, length.out=ceiling(paletteLength/2) + 1), 
              seq(max(scale(t(wide_counts)))/paletteLength, max(scale(t(wide_counts))), length.out=floor(paletteLength/2)))
```

Move the order of columns to be in time order (legal rotating of the dendrogram).

```{r class.source="bg-info", engine='R', eval=F, echo=T}
cluster_cols = hclust(dist(scale(t(wide_counts))))
cluster_cols$order = cluster_cols$order[c(1:12, 17:20, 13:16)]
```

Plot.

```{r class.source="bg-info", engine='R', eval=F, echo=T}
pdf("ATAC_counts_heatmap_FDR_0.01.pdf", width = 8, height = 5)
pheatmap(wide_counts, scale = "row", show_rownames = F, show_colnames = F, 
         color = myColor, breaks=myBreaks,
         annotation_col = anno, annotation_colors = ann_colors,
         cluster_cols = cluster_cols)
dev.off()
```

## Count GATA motif instances in dynamic peaks across time points (Figure 3F)

Set up in R.

```{r class.source="bg-info", engine='R', eval=F, echo=T}
direc = '~/Library/CloudStorage/Box-Box/GuertinLab/TRPS1_timecourse_ATAC/'
setwd(direc)

library(tidyverse)
library(tidyr)
library(lattice)
library(tidyr)

PeaksWithMotif <- function(motif_overlaps, motif)
{
  result = motif_overlaps[rownames(motif_overlaps) == motif,]
  times = c("0.5hour", "1hour", "2hour", "4hour")
  conditions = c("activated", "activated_matched", "repressed_matched", "repressed")
  df = as.data.frame(matrix(nrow = length(conditions), ncol = length(times)))
  colnames(df) = times
  rownames(df) = conditions
  for (i in 1:length(times)) {
    for (j in 1:length(conditions)) {
      df[j,i] = result[,paste0("X", times[i], "_", conditions[j], "_with")] / 
        (result[,paste0("X", times[i], "_", conditions[j], "_without")] +
           result[,paste0("X", times[i], "_", conditions[j], "_with")])
    }
  }
  df = df[-3,]
  rownames(df) = c("Increased", "Unchanged", "Decreased")
  colnames(df) = sapply(strsplit(colnames(df), "hour"), "[", 1)
  df$class = factor(rownames(df), levels = c("Increased", "Unchanged", "Decreased"))
  df_long <- gather(df, time, Proportion, -class, factor_key=TRUE)
  print(ggplot(df_long, aes(y = time, x = class, fill = Proportion)) + 
    geom_tile() +
    geom_text(aes(label = round(Proportion, 2))) +
    scale_fill_gradient(low="white", high="black", limits=c(0, 1)) +
    xlab(NULL) +
    ylab("Time (hours)")) +
    theme_bw() +
    theme(text = element_text(size = 20))
}
```

Plot.

```{r class.source="bg-info", engine='R', eval=F, echo=T}
motif_overlaps = read.table("Overlaps.txt", header = T, row.names = 1)
head(motif_overlaps)
pdf("ATAC_TRPS1_motif_heatmap_timecourse.pdf", height = 3.5)
PeaksWithMotif(motif_overlaps, motif = "TRPS1_homer_uniprobe_jaspar_edited.txt")
dev.off()
```

# PRO-seq data pre-processing

For the initial basic processing steps, we used a pipeline we have thoroughly described elsewhere (https://github.com/guertinlab/Nascent_RNA_Methods). Please see the above GitHub repository for detailed explanations of the steps, as well as software dependencies and preprocessing steps (e.g., gene annotation file downloads).

## Set up

Log in to the cluster to perform the processing for each sample in parallel.

```{r engine='bash', eval=F, echo=TRUE}
ssh -Y ts2hx@rivanna.hpc.virginia.edu 
ijob -c 1 -A gioeli_lab -p standard --time=1-00:00:00
```

Make a directory for each sequencing run.

```{r engine='bash', eval=F, echo=TRUE}
mkdir -p TRPS1_timecourse_PRO
mkdir -p TRPS1_timecourse_PRO_2
mkdir -p TRPS1_timecourse_PRO_3
```

The script used in the next code chunk (220927_tallymer_generation.sh) is below:

```{r engine='bash', eval=F, echo=TRUE}
#! /bin/bash

module load genometools/1.5.10
read_size=40
genome=/project/genomes/Homo_sapiens/UCSC/hg38/Sequence/WholeGenomeFasta/genome.fa

mkdir -p $HOME/seqOutBias
cd $HOME/seqOutBias
$HOME/bin/seqOutBias seqtable $genome --read-size=$read_size
```

Make tallymer and table for seqOutBias (this takes a while).

```{r engine='bash', eval=F, echo=TRUE}
sbatch -p largemem -A gioeli_lab -t 1-00:00:00 --job-name tallymer -o tallymer.log \
    /scratch/ts2hx/scripts/220927_tallymer_generation.sh

exit
exit
```

## Download the raw data from the three sequencing runs, rename the files, and combine the reads

We sequenced the libraries 3 times, first on a NextSeq2000, and the next two runs on a NextSeq550. We found that the NextSeq2000 gave us many duplicate reads, which we attribute to the patterned flow cell and our small fragment sizes for PRO-seq. We first put each sequencing run into its own folder.

```{r engine='bash', eval=F, echo=TRUE}
cd /Volumes/External/Users/TScott/TRPS1_timecourse_PRO/
scp *.fastq.gz ts2hx@rivanna.hpc.virginia.edu:/scratch/ts2hx/TRPS1_timecourse_PRO/

ssh -Y ts2hx@rivanna.hpc.virginia.edu 
ijob -c 1 -A gioeli_lab -p standard --time=1-00:00:00
```

Rename files to remove the excess.

```{r engine='bash', eval=F, echo=TRUE}
cd /scratch/ts2hx/TRPS1_timecourse_PRO/

for i in *_R1_001.fastq.gz
do
name=$(echo $i | awk -F"_S[0-9]" '{print $1}')
echo $name
hyphenless=${name//-/_}
echo $hyphenless
newname=${hyphenless//05hour/0.5hour}
echo $newname
mv ${name}_*_R1_001.fastq.gz ${newname}_PE1.fastq.gz
mv ${name}_*_R2_001.fastq.gz ${newname}_PE2.fastq.gz
done

exit
exit
```

Run 2:

```{r engine='bash', eval=F, echo=TRUE}
cd /Volumes/External/Users/TScott/TRPS1_timecourse_PRO_2/
scp *.fastq.gz ts2hx@rivanna.hpc.virginia.edu:/scratch/ts2hx/TRPS1_timecourse_PRO_2
```

Run 3:

```{r engine='bash', eval=F, echo=TRUE}
scp /Volumes/External/Users/TScott/TRPS1_timecourse_PRO_3.zip ts2hx@rivanna.hpc.virginia.edu:/scratch/ts2hx/

ssh -Y ts2hx@rivanna.hpc.virginia.edu 
ijob -c 1 -A gioeli_lab -p standard --time=1-00:00:00

cd /scratch/ts2hx/
unzip TRPS1_timecourse_PRO_3.zip
mv *.fastq.gz TRPS1_timecourse_PRO_3/
rm TRPS1_timecourse_PRO_3.zip
```

Rename files to remove the excess.

```{r engine='bash', eval=F, echo=TRUE}
cd /scratch/ts2hx/TRPS1_timecourse_PRO_3/

for i in *05hour*
do
  prefix=$(echo $i | awk -F"_05hour_" '{print $1}')
  suffix=$(echo $i | awk -F"_05hour_" '{print $2}')
  mv $i ${prefix}_0.5hour_${suffix}
done
```

Combine the NextSeq550 reads to generate representative quality control metrics.

```{r engine='bash', eval=F, echo=TRUE}
for i in *_R1_001.fastq.gz
do
  name=$(echo $i | awk -F"_S" '{print $1}')
  cat ../TRPS1_timecourse_PRO_2/${name}_PE1.fastq.gz $i > ${name}_NextSeq550_PE1.fastq.gz
  cat ../TRPS1_timecourse_PRO_2/${name}_PE2.fastq.gz ${name}_*_R2_001.fastq.gz > ${name}_NextSeq550_PE2.fastq.gz
done
```

Combine all reads for use in downstream analysis.

```{r engine='bash', eval=F, echo=TRUE}
for i in *_R1_001.fastq.gz
do
  name=$(echo $i | awk -F"_S" '{print $1}')
  cat ../TRPS1_timecourse_PRO_2/${name}_combined_PE1.fastq.gz $i > ${name}_combined_PE1.fastq.gz
  cat ../TRPS1_timecourse_PRO_2/${name}_combined_PE2.fastq.gz ${name}_*_R2_001.fastq.gz > ${name}_combined_PE2.fastq.gz
done
```

## Generate a plot of quality control metrics (Figure S1)

The script used in the next code chunk (220927_PROseq_analysis_on_input_file.sh) is below:

```{r engine='bash', eval=F, echo=TRUE}
#! /bin/bash
UMI_length=8
read_size=40
cores=$SLURM_CPUS_PER_TASK
annotation_prefix=$HOME/gene_annotations/Homo_sapiens.GRCh38.104 
genome_index=/project/genomes/Homo_sapiens/UCSC/hg38/Sequence/Bowtie2Index/genome
prealign_rdna_index=$HOME/human_rDNA/human_rDNA
tallymer=$HOME/seqOutBias/genome.tal_${read_size}.gtTxt.gz
table=$HOME/seqOutBias/genome_${read_size}.4.2.2.tbl

module load cutadapt/3.4
module load intel/18.0 intelmpi/18.0 R/4.1.1
module load gcc/9.2.0 bowtie2/2.2.9 
module load samtools/1.12
module load wigtobigwig/2.8
module load bedtools/2.29.2
module load pigz/2.4

PATH=$HOME/bin:$PATH

echo $name
gunzip ${name}_PE1.fastq.gz
gunzip ${name}_PE2.fastq.gz
echo 'removing dual adapter ligations and calculating the fraction of adapter/adapters in' $name
cutadapt --cores=$cores -m $((UMI_length+2)) -O 1 -a TGGAATTCTCGGGTGCCAAGG ${name}_PE1.fastq \
    -o ${name}_PE1_noadap.fastq --too-short-output ${name}_PE1_short.fastq > ${name}_PE1_cutadapt.txt
cutadapt --cores=$cores -m $((UMI_length+10)) -O 1 -a GATCGTCGGACTGTAGAACTCTGAAC ${name}_PE2.fastq \
    -o ${name}_PE2_noadap.fastq --too-short-output ${name}_PE2_short.fastq > ${name}_PE2_cutadapt.txt
PE1_total=$(wc -l ${name}_PE1.fastq | awk '{print $1/4}')
PE1_w_Adapter=$(wc -l ${name}_PE1_short.fastq | awk '{print $1/4}')
AAligation=$(echo "scale=2 ; $PE1_w_Adapter / $PE1_total" | bc)
echo -e  "value\texperiment\tthreshold\tmetric" > ${name}_QC_metrics.txt
echo -e "$AAligation\t$name\t0.80\tAdapter/Adapter" >> ${name}_QC_metrics.txt
echo 'removing short RNA insertions in' $name
seqtk seq -L $((UMI_length+10)) ${name}_PE1_noadap.fastq > ${name}_PE1_noadap_trimmed.fastq
echo 'removing PCR duplicates from' $name
fqdedup -i ${name}_PE1_noadap_trimmed.fastq -o ${name}_PE1_dedup.fastq
PE1_noAdapter=$(wc -l ${name}_PE1_dedup.fastq | awk '{print $1/4}')
fastq_pair -t $PE1_noAdapter ${name}_PE1_dedup.fastq ${name}_PE2_noadap.fastq
echo 'calculating and plotting RNA insert sizes from' $name
flash -q --compress-prog=gzip --suffix=gz ${name}_PE1_dedup.fastq.paired.fq \
    ${name}_PE2_noadap.fastq.paired.fq -o ${name}
insert_size.R ${name}.hist ${UMI_length}
echo 'trimming off the UMI from' $name
seqtk trimfq -b ${UMI_length} ${name}_PE1_dedup.fastq | seqtk seq -r - > ${name}_PE1_processed.fastq
seqtk trimfq -e ${UMI_length} ${name}_PE2_noadap.fastq | seqtk seq -r - > ${name}_PE2_processed.fastq
echo 'aligning' $name 'to rDNA and removing aligned reads'
bowtie2 -p $((cores-2)) -x $prealign_rdna_index -U ${name}_PE1_processed.fastq 2>${name}_bowtie2_rDNA.log | \
    samtools sort -n - | samtools fastq -f 0x4 - > ${name}_PE1.rDNA.fastq
reads=$(wc -l ${name}_PE1.rDNA.fastq | awk '{print $1/4}')
fastq_pair -t $reads ${name}_PE1.rDNA.fastq ${name}_PE2_processed.fastq
echo 'aligning' $name 'to the genome'
bowtie2 -p $((cores-2)) --maxins 1000 -x $genome_index --rf -1 ${name}_PE1.rDNA.fastq.paired.fq \
    -2 ${name}_PE2_processed.fastq.paired.fq 2>${name}_bowtie2.log | \
    samtools view -b - | samtools sort - -o ${name}.bam
PE1_prior_rDNA=$(wc -l ${name}_PE1_processed.fastq | awk '{print $1/4}')
PE1_post_rDNA=$(wc -l ${name}_PE1.rDNA.fastq | awk '{print $1/4}')
total_rDNA=$(echo "$(($PE1_prior_rDNA-$PE1_post_rDNA))")
concordant_pe1=$(samtools view -c -f 0x42 ${name}.bam)
total=$(echo "$(($concordant_pe1+$total_rDNA))")
rDNA_alignment=$(echo "scale=2 ; $total_rDNA / $total" | bc)
echo -e "$rDNA_alignment\t$name\t0.10\trDNA Alignment Rate" >> ${name}_QC_metrics.txt
map_pe1=$(samtools view -c -f 0x42 ${name}.bam)
pre_alignment=$(wc -l ${name}_PE1.rDNA.fastq.paired.fq | awk '{print $1/4}')
alignment_rate=$(echo "scale=2 ; $map_pe1 / $pre_alignment" | bc)
echo -e "$alignment_rate\t$name\t0.80\tAlignment Rate" >> ${name}_QC_metrics.txt
echo 'plotting and calculating complexity for' $name
fqComplexity -i ${name}_PE1_noadap_trimmed.fastq
echo 'calculating and plotting theoretical sequencing depth'
echo 'to achieve a defined number of concordantly aligned reads for' $name
PE1_total=$(wc -l ${name}_PE1.fastq | awk '{print $1/4}')
PE1_noadap_trimmed=$(wc -l ${name}_PE1_noadap_trimmed.fastq | awk '{print $1/4}')
factorX=$(echo "scale=2 ; $PE1_noadap_trimmed / $PE1_total" | bc)
echo fraction of reads that are not adapter/adapter ligation products or below 10 base inserts
echo $factorX
PE1_dedup=$(wc -l ${name}_PE1_dedup.fastq | awk '{print $1/4}')
factorY=$(echo "scale=2 ; $concordant_pe1 / $PE1_dedup" | bc)
fqComplexity -i ${name}_PE1_noadap_trimmed.fastq -x $factorX -y $factorY
echo 'Separating paired end reads and creating genomic BED and bigWig intensity files for' $name
mkdir ${name}_seqOutBias
cd ${name}_seqOutBias
seqOutBias scale $table ../${name}.bam --no-scale --stranded --bed-stranded-positive --only-paired --tail-edge \
    --bw=$name.bigWig --bed=$name.bed --out-split-pairends --read-size=$read_size --tallymer=$tallymer
cd ..
mv ${name}_seqOutBias/${name}* .
rm -r ${name}_seqOutBias
grep -v "random" ${name}_not_scaled_PE1.bed | grep -v "chrUn" | grep -v "chrEBV" | sort -k1,1 -k2,2n > \
    ${name}_tmp.txt && mv ${name}_tmp.txt ${name}_not_scaled_PE1.bed 
mapBed -null "0" -s -a $annotation_prefix.pause.bed -b ${name}_not_scaled_PE1.bed | \
    awk '$7>0' | sort -k5,5 -k7,7nr | sort -k5,5 -u > ${name}_pause.bed
join -1 5 -2 5 ${name}_pause.bed $annotation_prefix.bed | \
    awk '{OFS="\t";} $2==$8 && $6==$12 {print $2, $3, $4, $1, $6, $7, $9, $10}' | \
    awk '{OFS="\t";} $5 == "+" {print $1,$2+480,$8,$4,$6,$5} $5 == "-" {print $1,$7,$2 - 380,$4,$6,$5}' | \
    awk  '{OFS="\t";} $3>$2 {print $1,$2,$3,$4,$5,$6}' | \
    sort -k1,1 -k2,2n > ${name}_pause_counts_body_coordinates.bed
mapBed -null "0" -s -a ${name}_pause_counts_body_coordinates.bed -b ${name}_not_scaled_PE1.bed | \
    awk '$7>0' | awk '{OFS="\t";} {print $1,$2,$3,$4,$5,$6,$7,$5/100,$7/($3 - $2)}' | \
    awk '{OFS="\t";} {print $1,$2,$3,$4,$5,$6,$7,$8,$9,$8/$9}' > ${name}_pause_body.bed
pause_index.R ${name}_pause_body.bed
echo 'Calculating exon density / intron density as a metric for nascent RNA purity for' $name
mapBed -null "0" -s -a $annotation_prefix.introns.bed -b ${name}_not_scaled_PE1.bed | awk '$7>0' | \
    awk '{OFS="\t";} {print $1,$2,$3,$5,$5,$6,$7,($3 - $2)}' > ${name}_intron_counts.bed
mapBed -null "0" -s -a $annotation_prefix.no.first.exons.named.bed -b ${name}_not_scaled_PE1.bed | awk '$7>0' | \
    awk '{OFS="\t";} {print $1,$2,$3,$4,$4,$6,$7,($3 - $2)}' > ${name}_exon_counts.bed
exon_intron_ratio.R ${name}_exon_counts.bed ${name}_intron_counts.bed
echo 'Counting reads in genes for' $name
echo -e "\t${name}" > ${name}_gene_counts.txt
mapBed -null "0" -s -a ${annotation_prefix}_sorted.bed -b ${name}_not_scaled_PE1.bed | \
    awk '{OFS="\t";} {print $4,$7}' >> ${name}_gene_counts.txt
rm ${name}_PE1_short.fastq
rm ${name}_PE2_short.fastq
rm ${name}_PE1_noadap.fastq
rm ${name}_PE2_noadap.fastq
rm ${name}_PE1_noadap_trimmed.fastq
rm ${name}_PE1_dedup.fastq
rm ${name}_PE1_processed.fastq
rm ${name}_PE2_processed.fastq
rm ${name}_PE1_dedup.fastq.paired.fq
rm ${name}_PE2_noadap.fastq.paired.fq
rm ${name}_PE1_dedup.fastq.single.fq
rm ${name}_PE2_noadap.fastq.single.fq
rm ${name}_PE1.rDNA.fastq.paired.fq
rm ${name}_PE1.rDNA.fastq.single.fq
rm ${name}_PE2_processed.fastq.paired.fq
rm ${name}_PE2_processed.fastq.single.fq
rm ${name}.extendedFrags.fastq.gz
rm ${name}.notCombined_1.fastq.gz
rm ${name}.notCombined_2.fastq.gz
pigz ${name}_PE1.fastq
pigz ${name}_PE2.fastq
```

Run the above script on each sample in parallel.

```{r engine='bash', eval=F, echo=TRUE}
for i in *_NextSeq550_PE1.fastq.gz
do
  name=`basename $i _PE1.fastq.gz`
  sbatch -p standard -A gioeli_lab -t 4:00:00 -N 1 -n 1 --cpus-per-task=20 \
    --job-name proseq-analysis -o ${name}_proseq.log --export=ALL,i=$i,name=$name \
    /scratch/ts2hx/scripts/220927_PROseq_analysis_on_input_file.sh
  sleep 1
done
```

Plot the QC metrics.

```{r engine='bash', eval=F, echo=TRUE}
module load intel/18.0 intelmpi/18.0 R/4.1.1
PATH=$HOME/bin:$PATH
rm TRPS1_timecourse_PRO_NextSeq550_QC_metrics.txt
cat *QC_metrics.txt | awk '!x[$0]++' > TRPS1_timecourse_PRO_NextSeq550_QC_metrics.txt 
plot_all_metrics.R TRPS1_timecourse_PRO_NextSeq550_QC_metrics.txt TRPS1_timecourse_PRO_NextSeq550
paste -d'\t' *NextSeq550_gene_counts.txt > TRPS1_timecourse_PRO_gene_counts_NextSeq550.txt
```

## Process the combined reads

The script used in the next code chunk (220928_PROseq_analysis_on_input_file_no_QC_cut_PE1_to_48.sh) is below:

```{r engine='bash', eval=F, echo=TRUE}
#! /bin/bash
UMI_length=8
read_size=40
cores=$SLURM_CPUS_PER_TASK
annotation_prefix=$HOME/gene_annotations/Homo_sapiens.GRCh38.104 
genome_index=/project/genomes/Homo_sapiens/UCSC/hg38/Sequence/Bowtie2Index/genome
prealign_rdna_index=$HOME/human_rDNA/human_rDNA
tallymer=$HOME/seqOutBias/genome.tal_${read_size}.gtTxt.gz
table=$HOME/seqOutBias/genome_${read_size}.4.2.2.tbl

module load cutadapt/3.4
module load intel/18.0 intelmpi/18.0 R/4.1.1
module load gcc/9.2.0 bowtie2/2.2.9
module load samtools/1.12
module load wigtobigwig/2.8
module load bedtools/2.29.2
module load pigz/2.4

PATH=$HOME/bin:$PATH

echo $name
gunzip ${name}_PE1.fastq.gz
gunzip ${name}_PE2.fastq.gz
echo 'removing dual adapter ligations and calculating the fraction of adapter/adapters in' $name
cutadapt --cores=$cores -m $((UMI_length+10)) -l 48 -O 1 -a TGGAATTCTCGGGTGCCAAGG ${name}_PE1.fastq \
    -o ${name}_PE1_noadap_trimmed.fastq
cutadapt --cores=$cores -m $((UMI_length+10)) -O 1 -a GATCGTCGGACTGTAGAACTCTGAAC ${name}_PE2.fastq \
    -o ${name}_PE2_noadap.fastq
pigz ${name}_PE1.fastq
pigz ${name}_PE2.fastq
echo 'removing PCR duplicates from' $name
fqdedup -i ${name}_PE1_noadap_trimmed.fastq -o ${name}_PE1_dedup.fastq
rm ${name}_PE1_noadap_trimmed.fastq
echo 'trimming off the UMI from' $name
seqtk trimfq -b ${UMI_length} ${name}_PE1_dedup.fastq | seqtk seq -r - > ${name}_PE1_processed.fastq
seqtk trimfq -e ${UMI_length} ${name}_PE2_noadap.fastq | seqtk seq -r - > ${name}_PE2_processed.fastq
rm ${name}_PE2_noadap.fastq
rm ${name}_PE1_dedup.fastq
echo 'aligning' $name 'to rDNA and removing aligned reads'
bowtie2 -p $((cores-2)) -x $prealign_rdna_index -U ${name}_PE1_processed.fastq 2>${name}_bowtie2_rDNA.log | \
    samtools sort -n - | samtools fastq -f 0x4 - > ${name}_PE1.rDNA.fastq
rm ${name}_PE1_processed.fastq
reads=$(wc -l ${name}_PE1.rDNA.fastq | awk '{print $1/4}')
fastq_pair -t $reads ${name}_PE1.rDNA.fastq ${name}_PE2_processed.fastq
rm ${name}_PE1.rDNA.fastq
rm ${name}_PE2_processed.fastq
rm ${name}_PE1.rDNA.fastq.single.fq
rm ${name}_PE2_processed.fastq.single.fq
echo 'aligning' $name 'to the genome'
bowtie2 -p $((cores-2)) --maxins 1000 -x $genome_index --rf -1 ${name}_PE1.rDNA.fastq.paired.fq \
    -2 ${name}_PE2_processed.fastq.paired.fq 2>${name}_bowtie2.log | \
    samtools view -b - | samtools sort - -o ${name}.bam
rm ${name}_PE1.rDNA.fastq.paired.fq
rm ${name}_PE2_processed.fastq.paired.fq
echo 'Separating paired end reads and creating genomic BED and bigWig intensity files for' $name
mkdir ${name}_seqOutBias
cd ${name}_seqOutBias
seqOutBias scale $table ../${name}.bam --no-scale --stranded --bed-stranded-positive --only-paired --tail-edge \
    --bw=$name.bigWig --bed=$name.bed --out-split-pairends --read-size=$read_size --tallymer=$tallymer
cd ..
mv ${name}_seqOutBias/${name}* .
rm -r ${name}_seqOutBias
grep -v "random" ${name}_not_scaled_PE1.bed | grep -v "chrUn" | grep -v "chrEBV" | sort -k1,1 -k2,2n > \
    ${name}_tmp.txt && mv ${name}_tmp.txt ${name}_not_scaled_PE1.bed 
echo 'Counting reads in genes for' $name
echo -e "\t${name}" > ${name}_gene_counts.txt
mapBed -null "0" -s -a ${annotation_prefix}_sorted.bed -b ${name}_not_scaled_PE1.bed | \
    awk '{OFS="\t";} {print $4,$7}' >> ${name}_gene_counts.txt
```

Run the above script on each sample in parallel.

```{r engine='bash', eval=F, echo=TRUE}
for i in *_combined_PE1.fastq.gz
do
  name=`basename $i _PE1.fastq.gz`
  sbatch -p standard -A gioeli_lab -t 4:00:00 -N 1 -n 1 --cpus-per-task=20 \
    --job-name proseq-analysis -o ${name}_proseq.log --export=ALL,i=$i,name=$name \
    /scratch/ts2hx/scripts/220928_PROseq_analysis_on_input_file_no_QC_cut_PE1_to_48.sh
  sleep 1
done
```

Combine the reads into one file.

```{r engine='bash', eval=F, echo=TRUE}
paste -d'\t' *combined_gene_counts.txt > TRPS1_timecourse_PRO_gene_counts_combined.txt
```

## Scale and merge bigWigs for use in the genome browser

The script used in the next code chunk (230403_PRO_scale_bigWig_whole_fragment.sh) is below. It scales each bigWig based on the read depth, broken down by strand.

```{r engine='bash', eval=F, echo=TRUE}
#! /bin/bash
module load samtools/1.12 deeptools/3.5.1 

name=$(echo $1 | awk -F".bam" '{print $1}')

# include reads that are 1st in a pair (64) and properly paired (2);
# exclude reads that are mapped to the reverse strand (16)
samtools view -b -f 66 -F 16 ${name}.bam > ${name}.fwd1.bam

# include reads that are mapped to the reverse strand (16),
# second in a pair (128), and properly paired (2)
samtools view -b -f 146 ${name}.bam > ${name}.fwd2.bam

# combine the temporary files
samtools merge -f ${name}.fwd.bam ${name}.fwd1.bam ${name}.fwd2.bam

# index the filtered BAM file
samtools index ${name}.fwd.bam

# run bamCoverage
bamCoverage --bam ${name}.fwd.bam -bs 10 -p 10 -e --normalizeUsing BPM -o ${name}_whole_fragment_plus_scaled.bigWig

# remove the temporary files
rm ${name}.fwd*


# include reads that are 2nd in a pair (128) and properly paired (2);
# exclude reads that are mapped to the reverse strand (16)
samtools view -b -f 130 -F 16 ${name}.bam > ${name}.rev1.bam

# include reads that are mapped to the reverse strand (16),
# first in a pair (64), and properly paired (2)
samtools view -b -f 82 ${name}.bam > ${name}.rev2.bam

# combine the temporary files
samtools merge -f ${name}.rev.bam ${name}.rev1.bam ${name}.rev2.bam

# index the filtered BAM file
samtools index ${name}.rev.bam

# run bamCoverage
bamCoverage --bam ${name}.rev.bam -bs 10 -p 10 -e --normalizeUsing BPM -o ${name}_whole_fragment_minus_scaled.bigWig  

# remove the temporary files
rm ${name}.rev*
```

Run the above script on each sample in parallel.

```{r engine='bash', eval=F, echo=TRUE}
for i in *_combined.bam
do
  name=$(echo $i | awk -F".bam" '{print $1}')
  sbatch -p standard -A gioeli_lab -t 1:00:00 --cpus-per-task=10 --job-name bamCoverage -o ${name}_bamCoverage.log \
    --wrap="sh /scratch/ts2hx/scripts/230403_PRO_scale_bigWig_whole_fragment.sh $i"
  sleep 1
done
```

The script used in the next code chunk (230403_PRO_to_browser_whole_fragment.sh) is below. It merges the scaled bigWigs across replicates into one bigWig and one bedGraph per condition.

```{r engine='bash', eval=F, echo=TRUE}
#! /bin/bash
directory=/scratch/$USER/TRPS1_timecourse_PRO_3

PATH=$HOME/bin:$PATH

cd $directory

module load ucsc-tools/3.7.4

name=$(echo $1 | awk -F"T47D_Clone28_" '{print $2}' | awk -F"_rep2" '{print $1}')
strand=$(echo $1 | awk -F"rep2_combined_whole_fragment_" '{print $2}' | awk -F"_scaled.bigWig" '{print $1}')
echo $name
echo $strand
files=$(ls T47D_Clone28_${name}_rep*_combined_whole_fragment_${strand}_scaled.bigWig)
echo $files
if [ "$strand" == "plus" ]
then
echo "track type=bedGraph name=T47D_PRO_${name}_plus color=255,0,0 alwaysZero=on visibility=full" > T47D_${name}_${strand}_temp.txt
fi
if [ "$strand" == "minus" ]
then
echo "track type=bedGraph name=T47D_PRO_${name}_minus color=0,0,255 alwaysZero=on visibility=full" > T47D_${name}_${strand}_temp.txt
fi
count=$(ls T47D_Clone28_${name}_rep*_combined_whole_fragment_${strand}_scaled.bigWig | wc -l | bc)
scaleall=$(bc <<< "scale=4 ; 1.0 / $count")
echo $count
echo $scaleall
name=T47D_${name}
bigWigMerge $files ${name}_${strand}_tmp.bg
normalize_bedGraph.py -i ${name}_${strand}_tmp.bg -s $scaleall -o ${name}_${strand}_scaled.bg
LC_COLLATE=C sort -k1,1 -k2,2n ${name}_${strand}_scaled.bg > ${name}_${strand}_scaled_sorted.bg
cat ${name}_${strand}_temp.txt ${name}_${strand}_scaled_sorted.bg | \
  grep -v "random" | grep -v "chrUn" | grep -v "chrEBV" | grep -v "chrM" | grep -v "alt" > \
  ${name}_${strand}_scaled.bedGraph
rm ${name}_${strand}_tmp.bg
rm ${name}_${strand}_temp.txt
rm ${name}_${strand}_scaled.bg
rm ${name}_${strand}_scaled_sorted.bg
head ${name}_${strand}_scaled.bedGraph
bedGraphToBigWig ${name}_${strand}_scaled.bedGraph hg38.chrom.sizes ${name}_${strand}_combined_normalized.bigWig
gzip -f ${name}_${strand}_scaled.bedGraph
```

Run the above script on each sample in parallel.

```{r engine='bash', eval=F, echo=TRUE}
for i in T47D_Clone28_*_rep2_combined_whole_fragment_*_scaled.bigWig
do
  name=$(echo $i | awk -F"_scaled.bigWig" '{print $1}')
  sbatch -p largemem -A gioeli_lab -t 4:00:00 -N 1 -n 1 --job-name to_browser -o ${name}_to_browser.log \
  --wrap="sh /scratch/ts2hx/scripts/230403_PRO_to_browser_whole_fragment.sh $i"
  sleep 1
done
```

## Leave the cluster environment, and copy files to your local computer

```{r engine='bash', eval=F, echo=TRUE}
exit
exit

mkdir -p ~/Library/CloudStorage/Box-Box/GuertinLab/TRPS1_timecourse_PRO_3/
cd ~/Library/CloudStorage/Box-Box/GuertinLab/TRPS1_timecourse_PRO_3/

scp ts2hx@rivanna.hpc.virginia.edu:/scratch/ts2hx/TRPS1_timecourse_PRO_3/*.pdf .
scp ts2hx@rivanna.hpc.virginia.edu:/scratch/ts2hx/TRPS1_timecourse_PRO_3/TRPS1_timecourse_PRO_NextSeq550_QC_metrics.txt .
scp ts2hx@rivanna.hpc.virginia.edu:/scratch/ts2hx/TRPS1_timecourse_PRO_3/TRPS1_timecourse_PRO_gene_counts_NextSeq550.txt .
scp ts2hx@rivanna.hpc.virginia.edu:/scratch/ts2hx/TRPS1_timecourse_PRO_3/TRPS1_timecourse_PRO_gene_counts_combined.txt .
scp ts2hx@rivanna.hpc.virginia.edu:/scratch/ts2hx/TRPS1_timecourse_PRO_3/*us_scaled.bedGraph.gz .
scp ts2hx@rivanna.hpc.virginia.edu:/scratch/ts2hx/TRPS1_timecourse_PRO_3/*us_combined_normalized.bigWig .
``` 

# PRO-seq analysis

## Composite plot of PRO signal around TRPS1 ChIP-seq peaks (Figure 3G)

Set up.

```{r engine='bash', eval=F, echo=TRUE}
ssh -Y ts2hx@rivanna.hpc.virginia.edu 
ijob -c 1 -A gioeli_lab -p standard --cpus-per-task=20 --time=12:00:00
main=/scratch/ts2hx/ChIP/results
cd $main
mkdir -p heatmaps
cd heatmaps

module load deeptools/3.5.1
```

Make the matrix (starting with the bed file from the matrix generated for ChIP).

```{r engine='bash', eval=F, echo=TRUE}
computeMatrix reference-point --referencePoint center -b 500 -a 500 -p 20 --missingDataAsZero \
  -R TRPS1_peaks_sorted_for_heatmap.bed \
  -S /scratch/ts2hx/TRPS1_timecourse_PRO_3/T47D_0hour_plus_combined_normalized.bigWig \
  /scratch/ts2hx/TRPS1_timecourse_PRO_3/T47D_0hour_minus_combined_normalized.bigWig \
  /scratch/ts2hx/TRPS1_timecourse_PRO_3/T47D_0.5hour_plus_combined_normalized.bigWig \
  /scratch/ts2hx/TRPS1_timecourse_PRO_3/T47D_0.5hour_minus_combined_normalized.bigWig \
  -o matrix_PRO_TRPS1_peaks.gz
```

Plot the composites.

```{r engine='bash', eval=F, echo=TRUE}
plotProfile -m matrix_PRO_TRPS1_peaks.gz -out profile_PRO_TRPS1_peaks.pdf \
    --regionsLabel "Functional TRPS1 peaks" --perGroup --colors "#8B0000" "#00008B" "#FF7F7F" "#7F7FFF" \
    --samplesLabel "DMSO plus strand" "DMSO minus strand" "dTAG plus strand" "dTAG minus strand" 
```

Leave the cluster environment, and copy files to your local computer.

```{r engine='bash', eval=F, echo=TRUE}
exit
exit

cd ~/Library/CloudStorage/Box-Box/GuertinLab/ChIP/results
scp -r ts2hx@rivanna.hpc.virginia.edu:/scratch/ts2hx/ChIP/results/heatmaps .
```

## Cluster dynamic genes (Figure 4A,B)

Set up in R.

```{r class.source="bg-info", engine='R', eval=F, echo=T}
direc = "~/Library/CloudStorage/Box-Box/GuertinLab/TRPS1_timecourse_PRO_3/"
setwd(direc)

library(lattice)
library(DESeq2)
library(viridis)
library(tidyverse)
library(latticeExtra)
library(msigdbr)
library(clusterProfiler)
library(fgsea)
library(enrichplot)
library(EnhancedVolcano)
library(clusterProfiler)
library(pheatmap)
library(dendsort)
library(RColorBrewer)
library(DEGreport)
library(dplyr)
library(tidyr)
library(ggplot2)
library(data.table)

source('https://raw.githubusercontent.com/mjg54/znf143_pro_seq_analysis/master/docs/ZNF143_functions.R')

cdf.deseq.df <- function(df, genes = gene.file, chip.peaks = chip.peaks) {
  bed.tss.activated = filter.deseq.into.bed(df, genes, cat = "Activated")
  paste(head(bed.tss.activated))
  bed.tss.unchanged = filter.deseq.into.bed(df, genes, cat = "Unchanged")
  bed.tss.repressed = filter.deseq.into.bed(df, genes, cat = "Repressed")
  
  peaks = chip.peaks
  print(head(peaks))
  act.distance = bedTools.closest(bed1 = bed.tss.activated, bed2 = peaks[,c(1:3)], opt.string = '-D a')
  unreg.distance = bedTools.closest(bed1 = bed.tss.unchanged, bed2 = peaks[,c(1:3)], opt.string = '-D a')
  rep.distance = bedTools.closest(bed1 = bed.tss.repressed, bed2 = peaks[,c(1:3)], opt.string = '-D a')
  
  df.up.can = cbind(act.distance[,c(4, 10)], "Activated")
  df.un.can = cbind(unreg.distance[,c(4, 10)], "Unchanged")
  df.dn.can = cbind(rep.distance[,c(4, 10)], "Repressed")
  
  colnames(df.up.can) = c(colnames(df.up.can)[1:2], 'status')
  colnames(df.un.can) = c(colnames(df.up.can)[1:2], 'status')
  colnames(df.dn.can) = c(colnames(df.up.can)[1:2], 'status')
  
  df.all = rbind(df.up.can, df.un.can, df.dn.can)
  return(df.all)
}

filter.deseq.into.bed <- function(deseq.df, gene.file, cat = 'R1881 Activated') {
  deseq.df = deseq.df[deseq.df$status == cat,]
  #print(dim(deseq.df))
  #scientific notation was messing this up occasionally
  x = gene.file$V4
  #print(length(x))
  y = gene.file[x %in% rownames(deseq.df),]
  #print(dim(y))
  z = get.tss(y)
  #print(dim(z))
  return(z)
}

#bedTools.closest <- function(functionstring="/anaconda3/bin/closestBed",bed1,bed2,opt.string="") {
bedTools.closest <- function(functionstring="/usr/local/anaconda3/bin/closestBed",bed1,bed2,opt.string="") {
  
  options(scipen =99) # not to use scientific notation when writing out
  
  #write bed formatted dataframes to tempfile
  write.table(bed1,file= 'a.file.bed', quote=F,sep="\t",col.names=F,row.names=F)
  write.table(bed2,file= 'b.file.bed', quote=F,sep="\t",col.names=F,row.names=F)
  
  # create the command string and call the command using system()
  command1=paste('sort -k1,1 -k2,2n', 'a.file.bed', '> a.file.sorted.bed')
  cat(command1,"\n")
  try(system(command1))
  command2=paste('sort -k1,1 -k2,2n', 'b.file.bed', '> b.file.sorted.bed')
  cat(command2,"\n")
  try(system(command2))
  
  command=paste(functionstring, opt.string,"-a",'a.file.sorted.bed',"-b",'b.file.sorted.bed',">",'out.file.bed',sep=" ")
  cat(command,"\n")
  try(system(command))
  
  res=read.table('out.file.bed',header=F, comment.char='')
  
  command3=paste('rm', 'a.file.bed', 'b.file.bed', 'a.file.sorted.bed', 'b.file.sorted.bed', 'out.file.bed')
  cat(command3,"\n")
  try(system(command3))
  
  colnames(res) = c(colnames(bed1), colnames(bed2)[1:ncol(bed2)], 'dis' )
  return(res)
}

#Viridis color scheme
col = viridis(6)

#For converting gene names
gene.file = read.table("~/Library/CloudStorage/Box-Box/GuertinLab/ER_Antagonists_R/Homo_sapiens.GRCh38.104.bed", sep = '\t', header = FALSE)
`%notin%` <- Negate(`%in%`)
gene.file = gene.file[gene.file$V5 %notin% c("havana", "havana_tagene", "ensembl_havana"),]
gene.symbol = gene.file[,c(4,5)]
colnames(gene.symbol) = c("gene", "symbol")
```

Read in the counts table and change the column names. Here we focus on the early time points.

```{r class.source="bg-info", engine='R', eval=F, echo=T}
#DESeq
x = read.table("TRPS1_timecourse_PRO_gene_counts_Combined.txt", sep = '\t', header = TRUE)
rownames(x) = x[,1]
x = x[,seq(2,to=ncol(x),by=2)]
x = x[,!grepl("24hour", colnames(x))]
```

Run DESeq2.

```{r class.source="bg-info", engine='R', eval=F, echo=T}
time = factor(sapply(strsplit(colnames(x), '_'), '[', 3), levels = c("0hour", "0.5hour", "1hour", "2hour", "4hour"))
rep = factor(sapply(strsplit(colnames(x), 'rep'), '[', 2))
deseq.df = DESeqDataSetFromMatrix(x, cbind.data.frame(time, rep), ~ rep + time)
deseq.df = DESeq(deseq.df)
```

Run the likelihood ratio test to identify dynamic peaks over the time course.

```{r class.source="bg-info", engine='R', eval=F, echo=T}
dds.lrt = DESeq(deseq.df, test="LRT", reduced = ~ rep)
res.lrt = results(dds.lrt)
sum(res.lrt$padj < 0.1 & !is.na(res.lrt$padj))
```

Cluster the genes.

```{r class.source="bg-info", engine='R', eval=F, echo=T}
rld = rlogTransformation(dds.lrt)
rld_mat <- assay(rld)
siglrt.re = res.lrt[res.lrt$padj < 0.1 & !is.na(res.lrt$padj),]
cluster_rlog = rld_mat[rownames(siglrt.re),]
meta = cbind.data.frame(time, rep)
rownames(meta) = colnames(cluster_rlog)
clusters_lrt <- degPatterns(cluster_rlog, metadata = meta, minc = 0)
```

Set up a data frame for plotting.

```{r class.source="bg-info", engine='R', eval=F, echo=T}
plot.df = clusters_lrt$normalized 
plot.df$time = as.character(plot.df$time)
plot.df$time[plot.df$time == '0hour'] = 0
plot.df$time[plot.df$time == '0.5hour'] = 0.5
plot.df$time[plot.df$time == '1hour'] = 1
plot.df$time[plot.df$time == '2hour'] = 2
plot.df$time[plot.df$time == '4hour'] = 4
plot.df$time = as.numeric(plot.df$time)
plot.df = plot.df[order(plot.df$genes),]
plot.df = plot.df[order(plot.df$time),]
plot.df$cluster = paste('cluster', as.character(plot.df$cluster), sep = '')
head(plot.df)
save(plot.df, file = "plot.df.pro.no.24hour.Rdata")
```

Generate a dendrogram to check where we can merge clusters.

```{r class.source="bg-info", engine='R', eval=F, echo=T}
x = as.data.table(plot.df)
plot.df.cluster = dcast(x, genes + cluster ~ time, value.var="value")
avg.clusters = as.data.frame(matrix(nrow = 0, ncol = 4))
for (i in unique(plot.df.cluster$cluster)) {
  z = data.frame(matrix(colMeans(plot.df.cluster[plot.df.cluster$cluster == i,3:6]), 
                        ncol = 4, nrow = 1))
  rownames(z) = c(i)
  colnames(z) = as.character(colnames(plot.df.cluster)[3:6])
  avg.clusters = rbind(avg.clusters, z)
}
dd = dist(avg.clusters)
hc = hclust(dd, method = "complete")
pdf('Dendrogram_PRO_no_24hour.pdf', width=8, height=5)
plot(hc, xlab = "Clusters", main = ' ', hang = -1)
abline(h = 1.85, lty = 2)
dev.off()
```

Merge clusters.

```{r class.source="bg-info", engine='R', eval=F, echo=T}
gradual.down = plot.df[plot.df$cluster == 'cluster2' | 
                         plot.df$cluster == 'cluster7',]
transient.down = plot.df[plot.df$cluster == 'cluster3' |
                            plot.df$cluster == 'cluster9' |
                            plot.df$cluster == 'cluster12' |
                            plot.df$cluster == 'cluster4' |
                            plot.df$cluster == 'cluster18' |
                            plot.df$cluster == 'cluster16' |
                            plot.df$cluster == 'cluster17',]
oscillating.up = plot.df[plot.df$cluster == 'cluster11' | 
                       plot.df$cluster == 'cluster6' |
                       plot.df$cluster == 'cluster19',]
immediate.up = plot.df[plot.df$cluster == 'cluster10' |
                       plot.df$cluster == 'cluster14' |
                       plot.df$cluster == 'cluster15',]
transient.up = plot.df[plot.df$cluster == 'cluster1' |
                       plot.df$cluster == 'cluster8',]
gradual.up = plot.df[plot.df$cluster == 'cluster5' |
                       plot.df$cluster == 'cluster13',]

gradual.down$supercluster = 'Gradual Decrease' 
transient.down$supercluster = 'Transient Decrease' 
oscillating.up$supercluster = 'Oscillating Increase' 
immediate.up$supercluster = 'Immediate Increase' 
transient.up$supercluster = 'Transient Increase' 
gradual.up$supercluster = 'Gradual Increase' 
```

Make a data frame for plotting the superclusters.

```{r class.source="bg-info", engine='R', eval=F, echo=T}
plot.df.pro = rbind(gradual.down,
                    transient.down,
                    oscillating.up,
                    immediate.up,
                    transient.up,
                    gradual.up)
plot.df.pro$supercluster <- factor(plot.df.pro$supercluster, 
                                   levels = c("Oscillating Increase", "Immediate Increase", "Gradual Increase",
                                              "Transient Increase", "Gradual Decrease", "Transient Decrease"))
plot.df.pro$genes = as.factor(plot.df.pro$genes)
```

Assign the colors.

```{r class.source="bg-info", engine='R', eval=F, echo=T}
cat.colours = plot.df.pro[plot.df.pro$merge == 'one_group0hour',]
cat.colours$genes <- as.factor(cat.colours$genes)
cat.colours$supercluster <- as.factor(cat.colours$supercluster)
cat.colours$colour[grep("Increase", cat.colours$supercluster)] <- '#FF000016'
cat.colours$colour[grep("Decrease", cat.colours$supercluster)] <- '#0000FF16'
cat.colours$colour <- as.factor(cat.colours$colour)
cat.colours <- cat.colours[match(levels(plot.df.pro$genes), cat.colours$genes), ]
```

Plot.

```{r class.source="bg-info", engine='R', eval=F, echo=T}
pdf('pro_superclusters_transient_gradual_only.pdf', width=10, height=10)
trellis.par.set(box.umbrella = list(lty = 1, col="black", lwd=1),
                box.rectangle = list( lwd=1.0, col="black", alpha = 1.0),
                plot.symbol = list(col="black", lwd=1.0, pch ='.'))
print(xyplot(value ~  factor(time) | supercluster, group = genes,
             data = plot.df.pro[plot.df.pro$supercluster %in% levels(plot.df.pro$supercluster)[3:6],], type = c('l'),
             scales=list(x=list(cex=2,relation = "free", rot = 45),
                         y =list(cex=2, relation="free")),
             aspect=1.0, 
             between=list(y=0.5, x=0.5), 
             layout = c(2,2), 
             ylab = list(label = 'Scaled normalized PRO signal', cex=3), 
             xlab = list(label = 'Time (hours)', cex =3), 
             par.strip.text=list(cex=2),
             par.settings = list(superpose.symbol = list(pch = c(16), col=c('grey20'), cex =1),
                                 strip.background=list(col="grey80"),
                                 superpose.line = list(col = as.character(cat.colours$colour), lwd=c(1), lty = c(1))),
             panel = function(x, y, ...) {
               panel.xyplot(x, y, ...)
               panel.bwplot(x, y, pch = '|', horizontal = FALSE, box.width = .5,
                            do.out = F)
               panel.spline(x, y, col = 'black', lwd =3.0, ...) 
               
             })
)
dev.off()
```

## Over-representation analysis (Figure 4C,D)

Activated genes.

```{r class.source="bg-info", engine='R', eval=F, echo=T}
genes = plot.df.pro$genes[(plot.df.pro$supercluster == "Gradual Increase" | plot.df.pro$supercluster == "Transient Increase") & plot.df.pro$merge == "one_group0hour"]
m_t2g <- msigdbr(species = "Homo sapiens", category = "H") %>% 
  dplyr::select(gs_name, ensembl_gene)
set.seed(0)
em <- enricher(genes, TERM2GENE=m_t2g, pvalueCutoff = 0.1)
em$ID
em$p.adjust
fgseaResTidy <- em %>%
  as_tibble() %>%
  arrange(p.adjust)
print(fgseaResTidy, n = 100)
gse_top = fgseaResTidy
gse_top$Ratio_ratio = 
  (as.numeric(sapply(strsplit(gse_top$GeneRatio, "/"), "[", 1)) / 
     as.numeric(sapply(strsplit(gse_top$GeneRatio, "/"), "[", 2))) / 
  (as.numeric(sapply(strsplit(gse_top$BgRatio, "/"), "[", 1)) / 
     as.numeric(sapply(strsplit(gse_top$BgRatio, "/"), "[", 2)))
pdf("Hallmark_ORA_Combined_Increase.pdf", width = 14)
ggplot(gse_top, aes(reorder(ID, Ratio_ratio), Ratio_ratio, fill = log(p.adjust, base = 10))) +
  geom_col() +
  coord_flip() +
  scale_fill_gradient(low="#750000", high="#FF8A8A") +
  labs(y="Observed / Expected", x = NULL) + 
  theme_minimal() + 
  labs(fill = "log(padj)") +
  theme(text = element_text(size = 20),
        axis.text.x= element_text(size = 30)) 
dev.off()
```

Repressed genes.

```{r class.source="bg-info", engine='R', eval=F, echo=T}
genes = plot.df.pro$genes[(plot.df.pro$supercluster == "Gradual Decrease" | plot.df.pro$supercluster == "Transient Decrease") & plot.df.pro$merge == "one_group0hour"]
m_t2g <- msigdbr(species = "Homo sapiens", category = "H") %>% 
  dplyr::select(gs_name, ensembl_gene)
set.seed(0)
em <- enricher(genes, TERM2GENE=m_t2g, pvalueCutoff = 0.1)
em$ID
em$p.adjust
fgseaResTidy <- em %>%
  as_tibble() %>%
  arrange(p.adjust)
print(fgseaResTidy, n = 100)
gse_top = fgseaResTidy
gse_top$Ratio_ratio = 
  (as.numeric(sapply(strsplit(gse_top$GeneRatio, "/"), "[", 1)) / 
     as.numeric(sapply(strsplit(gse_top$GeneRatio, "/"), "[", 2))) / 
  (as.numeric(sapply(strsplit(gse_top$BgRatio, "/"), "[", 1)) / 
     as.numeric(sapply(strsplit(gse_top$BgRatio, "/"), "[", 2)))
pdf("Hallmark_ORA_Combined_Decrease.pdf", width = 14)
ggplot(gse_top, aes(reorder(ID, Ratio_ratio), Ratio_ratio, fill = log(p.adjust, base = 10))) +
  geom_col() +
  coord_flip() +
  scale_fill_gradient(low="#000075", high="#8A8AFF") +
  labs(y="Observed / Expected", x = NULL) + 
  theme_minimal() + 
  labs(fill = "log(padj)") +
  theme(text = element_text(size = 20),
        axis.text.x= element_text(size = 30)) 
dev.off()
```

# Integrative analysis

## CDFs of distance between dynamic genes and dynamic TRPS1-proximal ATAC peaks (Figure 4E,F)

Make a data frame with dynamic genes and unchanged genes.

```{r class.source="bg-info", engine='R', eval=F, echo=T}
#CDFs separated by TRPS1 peaks overlapping increased vs decreased ATAC peaks 
genes = plot.df.pro$genes[(plot.df.pro$supercluster == "Gradual Increase" | plot.df.pro$supercluster == "Transient Increase") & plot.df.pro$merge == "one_group0hour"]
activated = cbind.data.frame(genes, status = "Activated")
genes = plot.df.pro$genes[(plot.df.pro$supercluster == "Gradual Decrease" | plot.df.pro$supercluster == "Transient Decrease") & plot.df.pro$merge == "one_group0hour"]
repressed = cbind.data.frame(genes, status = "Repressed")
genes = rownames(res.lrt)[res.lrt$padj > 0.5 & !is.na(res.lrt$padj)]
unchanged = cbind.data.frame(genes, status = "Unchanged")

df.deseq.effects.lattice = rbind.data.frame(unchanged, activated, repressed)
rownames(df.deseq.effects.lattice) = df.deseq.effects.lattice$genes
```

Get the dynamic ATAC peaks.

```{r class.source="bg-info", engine='R', eval=F, echo=T}
x <- read.table("~/Library/CloudStorage/Box-Box/GuertinLab/TRPS1_timecourse_ATAC/Combined_ATAC_peak_counts.txt", sep = '\t', header = TRUE)
peak_qvalue = x[,5]

load("~/Library/CloudStorage/Box-Box/GuertinLab/TRPS1_timecourse_ATAC/deseq.df.ATAC.Rdata")
i="0.5hour"
res.deseq = results(deseq.df[peak_qvalue > 100,], contrast = c("time", i, "0hour"))
res.deseq$chr = sapply(strsplit(rownames(res.deseq), ":"), "[", 1)
res.deseq$start = sapply(strsplit(sapply(strsplit(rownames(res.deseq), ":"), "[", 2), "-"), "[", 1)
res.deseq$end = sapply(strsplit(sapply(strsplit(rownames(res.deseq), ":"), "[", 2), "-"), "[", 2)
res.deseq = res.deseq[, c(7:9,1:6)]
res.deseq$start = as.numeric(res.deseq$start) + 100
res.deseq$end = as.numeric(res.deseq$end) - 100
increasing = res.deseq[res.deseq$padj < 0.1 & !is.na(res.deseq$padj) & res.deseq$log2FoldChange > 0,]
decreasing = res.deseq[res.deseq$padj < 0.1 & !is.na(res.deseq$padj) & res.deseq$log2FoldChange < 0,]
```

Overlap with TRPS1 peaks.

```{r class.source="bg-info", engine='R', eval=F, echo=T}
chip.peaks = read.table('~/Library/CloudStorage/Box-Box/GuertinLab/ChIP/results/macs2/HA_DMSO_vs_dTAG_summits.bed')
chip.peaks = chip.peaks[chip.peaks$V5 > 30,]
TRPS1_increasing_ATAC_peaks = bedTools.intersect(bed1 = chip.peaks, bed2 = increasing, opt.string = "-wa -wb")
TRPS1_decreasing_ATAC_peaks = bedTools.intersect(bed1 = chip.peaks, bed2 = decreasing, opt.string = "-wa -wb")
```

Plot.

```{r class.source="bg-info", engine='R', eval=F, echo=T}
df.all = cdf.deseq.df(df = df.deseq.effects.lattice, genes = gene.file, chip.peaks = TRPS1_increasing_ATAC_peaks)
pdf("CDF_HA_ChIP_increasing_ATAC_by_gene_superclusters.pdf", height = 3.5, width = 4) 
ecdfplot(~log(abs(dis), base = 10), groups = status, data = df.all,
         auto.key = list(lines=TRUE, points=FALSE, space = "right"),
         col = col.lines,
         aspect = 1,
         scales=list(relation="free",alternating=c(1,1,1,1)),
         ylab = 'Cumulative Distribution Function',
         xlab = expression('log'[10]~'TRPS1 Distance from TSS'),
         between=list(y = 1.0),
         type = 'a',
         #xlim = c(0, 7.5),
         lwd = 2,
         par.settings = list(superpose.line = list(col = col.lines, lwd=3), 
                             strip.background=list(col="grey85")),
         panel = function(...) {
           panel.abline(v= 200, lty =2)
           panel.ecdfplot(...)
         })
dev.off()

df.all = cdf.deseq.df(df = df.deseq.effects.lattice, genes = gene.file, chip.peaks = TRPS1_decreasing_ATAC_peaks)
df.all = df.all[df.all$dis != -1,]
pdf("CDF_HA_ChIP_decreasing_ATAC_by_gene_superclusters.pdf", height = 3.5, width = 4) 
ecdfplot(~log(abs(dis), base = 10), groups = status, data = df.all,
         auto.key = list(lines=TRUE, points=FALSE, space = "right"),
         col = col.lines,
         aspect = 1,
         scales=list(relation="free",alternating=c(1,1,1,1)),
         ylab = 'Cumulative Distribution Function',
         xlab = expression('log'[10]~'TRPS1 Distance from TSS'),
         between=list(y = 1.0),
         type = 'a',
         #xlim = c(0, 7.5),
         lwd = 2,
         par.settings = list(superpose.line = list(col = col.lines, lwd=3), 
                             strip.background=list(col="grey85")),
         panel = function(...) {
           panel.abline(v= 200, lty =2)
           panel.ecdfplot(...)
         })
dev.off()
```

## Identification of ER target genes (Figure S2)

Set up in R.

```{r class.source="bg-info", engine='R', eval=F, echo=T}
setwd("~/Library/CloudStorage/Box-Box/GuertinLab/ER_Antagonists_R")

library(lattice)
library(DESeq2)
library(ggplot2)

cdf.deseq.df <- function(df, genes = gene.file, chip.peaks = chip.peaks) {
  bed.tss.activated = filter.deseq.into.bed(df, genes, cat = "Activated")
  bed.tss.unchanged = filter.deseq.into.bed(df, genes, cat = 'Not Activated')
  act.distance = bedTools.closest(bed1 = bed.tss.activated, bed2 = chip.peaks[,c(1:3)], opt.string = '-D a')
  unreg.distance = bedTools.closest(bed1 = bed.tss.unchanged, bed2 = chip.peaks[,c(1:3)], opt.string = '-D a')

  df.up.can = cbind(act.distance[,c(4, 10)], "Activated")
  df.un.can = cbind(unreg.distance[,c(4, 10)], "Not Activated")

  colnames(df.up.can) = c(colnames(df.up.can)[1:2], 'status')
  colnames(df.un.can) = c(colnames(df.up.can)[1:2], 'status')

  df.all = rbind(df.up.can, df.un.can)
  df.all$status = factor(df.all$status, levels = c("Activated", "Not Activated"))
  return(df.all)
}

filter.deseq.into.bed <- function(deseq.df, gene.file, cat = 'R1881 Activated') {
  deseq.df = deseq.df[deseq.df$treatment == cat,]
  #print(dim(deseq.df))
  #scientific notation was messing this up occasionally
  x = gene.file$V4
  #print(length(x))
  y = gene.file[x %in% rownames(deseq.df),]
  #print(dim(y))
  z = get.tss(y)
  #print(dim(z))
  return(z)
}

plot_cdf <- function(df.all, tf = "TRPS1", col.lines = c("#FF0000", "grey60", "#0000FF")) {
  ecdfplot(~log(abs(as.numeric(dis)), base = 10), groups = status, data = df.all,
           auto.key = list(lines=TRUE, points=FALSE),
           col = col.lines,
           aspect = 1,
           scales=list(relation="free",alternating=c(1,1,1,1)),
           ylab = 'Cumulative Distribution Function',
           xlab = bquote("log"[10]~.(tf)~"Distance from TSS"),
           between=list(y=1.0),
           type = 'a',
           xlim = c(0,7.5),
           lwd=2,
           par.settings = list(superpose.line = list(col = col.lines, lwd=3), 
                               strip.background=list(col="grey85")),
           panel = function(...) {
             panel.abline(v= 200, lty =2)
             panel.ecdfplot(...)
           })
}

col.lines = c("#FF0000", "grey60")

bedTools.closest <- function(functionstring="/usr/local/anaconda3/bin/closestBed",bed1,bed2,opt.string="") {
  
  options(scipen =99) # not to use scientific notation when writing out
  
  #write bed formatted dataframes to tempfile
  write.table(bed1,file= 'a.file.bed', quote=F,sep="\t",col.names=F,row.names=F)
  write.table(bed2,file= 'b.file.bed', quote=F,sep="\t",col.names=F,row.names=F)
  
  # create the command string and call the command using system()
  command1=paste('sort -k1,1 -k2,2n', 'a.file.bed', '> a.file.sorted.bed')
  cat(command1,"\n")
  try(system(command1))
  command2=paste('sort -k1,1 -k2,2n', 'b.file.bed', '> b.file.sorted.bed')
  cat(command2,"\n")
  try(system(command2))
  
  command=paste(functionstring, opt.string,"-a",'a.file.sorted.bed',"-b",'b.file.sorted.bed',">",'out.file.bed',sep=" ")
  cat(command,"\n")
  try(system(command))
  
  res=read.table('out.file.bed',header=F, comment.char='')
  
  command3=paste('rm', 'a.file.bed', 'b.file.bed', 'a.file.sorted.bed', 'b.file.sorted.bed', 'out.file.bed')
  cat(command3,"\n")
  try(system(command3))
  
  colnames(res) = c(colnames(bed1), colnames(bed2), 'dis' )
  return(res)
}

#For converting gene names
gene.file = read.table("~/Library/CloudStorage/Box-Box/GuertinLab/ER_Antagonists_R/Homo_sapiens.GRCh38.104.bed", sep = '\t', header = FALSE)
`%notin%` <- Negate(`%in%`)
gene.file = gene.file[gene.file$V5 %notin% c("havana", "havana_tagene", "ensembl_havana"),]
gene.symbol = gene.file[,c(4,5)]
colnames(gene.symbol) = c("gene", "symbol")
```

I used the counts table (Estrogen_treatment_PRO_gene_counts.txt) generated from a previous analysis, extensively described here: https://github.com/guertinlab/Nascent_RNA_Methods. Run DESeq2 with these counts.

```{r class.source="bg-info", engine='R', eval=F, echo=T}
x = read.table("Estrogen_treatment_PRO_gene_counts.txt", sep = '\t', header = TRUE)
rownames(x) = x[,1]
x = x[,seq(2,to=ncol(x),by=2)]
rep = factor(sapply(strsplit(colnames(x), '_rep'), '[', 2)) 
sample.conditions = factor(sapply(strsplit(sapply(strsplit(colnames(x), 'T47D_'), '[', 2), '_rep'), '[', 1)) 
deseq.df = DESeqDataSetFromMatrix(x, cbind.data.frame(rep, sample.conditions), ~ 0 + rep + sample.conditions)
deseq.df = DESeq(deseq.df)

res.deseq.estrogen = results(deseq.df, contrast = c("sample.conditions", "Starved_Estrogen", "Starved_DMSO"))
res.deseq.estrogen = res.deseq.estrogen[rownames(res.deseq.estrogen) %in% gene.symbol$gene,]
ma.df = as.data.frame(res.deseq.estrogen)
```

Plot. 

```{r class.source="bg-info", engine='R', eval=F, echo=T}
pdf("MA_plot_Estrogen_vs_DMSO_black_activated.pdf", width=3.83, height=3.83)
print(xyplot(ma.df$log2FoldChange ~ log(ma.df$baseMean, base=10),
             groups=(ma.df$padj < .1 & ma.df$log2FoldChange > 0 & !is.na(ma.df$padj)),
             col=c("grey60","black"), main="Differential PRO Expression", scales="free", aspect=1, pch=20, cex=0.25,
             ylab=expression("log"[2]~"PRO fold change"), xlab=expression("log"[10]~"Mean of Normalized Counts"),
             par.settings=list(par.xlab.text=list(cex=1.1,font=2), par.ylab.text=list(cex=1.1,font=2))))
dev.off()
```

## Cluster of dynamic ER target genes (Figure 5A)

Set up in R.

```{r class.source="bg-info", engine='R', eval=F, echo=T}
direc = "~/Library/CloudStorage/Box-Box/GuertinLab/TRPS1_timecourse_PRO_3/"
setwd(direc)

library(lattice)
library(DESeq2)
library(viridis)
library(tidyverse)
library(latticeExtra)
library(msigdbr)
library(clusterProfiler)
library(fgsea)
library(enrichplot)
library(EnhancedVolcano)
library(clusterProfiler)
library(pheatmap)
library(dendsort)
library(RColorBrewer)
library(DEGreport)
library(dplyr)
library(tidyr)
library(ggplot2)
library(data.table)

source('https://raw.githubusercontent.com/mjg54/znf143_pro_seq_analysis/master/docs/ZNF143_functions.R')

#Viridis color scheme
col = viridis(6)

#For converting gene names
gene.file = read.table("~/Library/CloudStorage/Box-Box/GuertinLab/ER_Antagonists_R/Homo_sapiens.GRCh38.104.bed", sep = '\t', header = FALSE)
`%notin%` <- Negate(`%in%`)
gene.file = gene.file[gene.file$V5 %notin% c("havana", "havana_tagene", "ensembl_havana"),]
gene.symbol = gene.file[,c(4,5)]
colnames(gene.symbol) = c("gene", "symbol")
```

Read in the counts table and change the column names.
```{r class.source="bg-info", engine='R', eval=F, echo=T}
x = read.table("TRPS1_timecourse_PRO_60kb_gene_counts.txt", sep = '\t', header = TRUE)
rownames(x) = x[,1]
x = x[,seq(2,to=ncol(x),by=2)]
```

Run DESeq2.

```{r class.source="bg-info", engine='R', eval=F, echo=T}
time = factor(sapply(strsplit(colnames(x), '_'), '[', 3), levels = c("0hour", "0.5hour", "1hour", "2hour", "4hour", "24hour"))
rep = factor(sapply(strsplit(colnames(x), 'rep'), '[', 2))
deseq.df = DESeqDataSetFromMatrix(x, cbind.data.frame(time, rep), ~ rep + time)
deseq.df = DESeq(deseq.df)
```

Run the likelihood ratio test to identify dynamic peaks over the time course.

```{r class.source="bg-info", engine='R', eval=F, echo=T}
dds.lrt = DESeq(deseq.df, test="LRT", reduced = ~ rep)
res.lrt = results(dds.lrt)
rld = rlogTransformation(dds.lrt)
rld_mat <- assay(rld)

sum(res.lrt$padj < 0.1 & !is.na(res.lrt$padj))
siglrt.re = res.lrt[res.lrt$padj < 0.1 & !is.na(res.lrt$padj),]
```

Intersect with ER target genes.

```{r class.source="bg-info", engine='R', eval=F, echo=T}
estrogen_response_genes = read.table("~/Library/CloudStorage/Box-Box/GuertinLab/ER_Antagonists_R/estrogen_activated_gene_names.txt", header = FALSE)$V1
estrogen_response_genes = gene.symbol$gene[gene.symbol$symbol %in% estrogen_response_genes]
siglrt.re.sets = siglrt.re[rownames(siglrt.re) %in% estrogen_response_genes,] 
```

Separate those that are activated at 30 minutes from those that are repressed.

```{r class.source="bg-info", engine='R', eval=F, echo=T}
res.deseq = results(deseq.df, contrast = c("time", "0.5hour", "0hour"))
sum(res.deseq$padj < 0.1 & !is.na(res.deseq$padj))
sum(res.deseq$padj < 0.1 & !is.na(res.deseq$padj) & rownames(res.deseq) %in% estrogen_response_genes)
act.res.deseq = res.deseq[res.deseq$padj < 0.1 & !is.na(res.deseq$padj) & res.deseq$log2FoldChange > 0 & rownames(res.deseq) %in% estrogen_response_genes,]
rep.res.deseq = res.deseq[res.deseq$padj < 0.1 & !is.na(res.deseq$padj) & res.deseq$log2FoldChange < 0 & rownames(res.deseq) %in% estrogen_response_genes,]
sig.res.deseq = rbind(act.res.deseq, rep.res.deseq)
```

Cluster the genes.

```{r class.source="bg-info", engine='R', eval=F, echo=T}
dim(sig.res.deseq)      
cluster_rlog = rld_mat[rownames(sig.res.deseq),]
meta = cbind.data.frame(time, rep)
rownames(meta) = colnames(cluster_rlog)
clusters_lrt <- degPatterns(cluster_rlog, metadata = meta, minc = 0)
```

Set up a data frame for plotting.

```{r class.source="bg-info", engine='R', eval=F, echo=T}
plot.df = clusters_lrt$normalized 
plot.df$Class[plot.df$genes %in% rownames(act.res.deseq)] <- "Activated at 30 minutes"
plot.df$Class[plot.df$genes %in% rownames(rep.res.deseq)] <- "Repressed at 30 minutes"
plot.df$time = as.character(plot.df$time)
plot.df$time[plot.df$time == '0hour'] = 0
plot.df$time[plot.df$time == '0.5hour'] = 0.5
plot.df$time[plot.df$time == '1hour'] = 1
plot.df$time[plot.df$time == '2hour'] = 2
plot.df$time[plot.df$time == '4hour'] = 4
plot.df$time[plot.df$time == '24hour'] = 24
plot.df$time = as.numeric(plot.df$time)
plot.df = plot.df[order(plot.df$genes),]
plot.df = plot.df[order(plot.df$time),]
plot.df$cluster = paste('cluster', as.character(plot.df$cluster), sep = '')
head(plot.df)

save(plot.df, file = "LRT_estrogen_response_gene_set_significant_at_30min_plot.df_60kb.RData")
load("LRT_estrogen_response_gene_set_significant_at_30min_plot.df_60kb.RData")
```

Assign the colors.

```{r class.source="bg-info", engine='R', eval=F, echo=T}
cat.colours = plot.df
cat.colours$colour[plot.df$Class == "Activated at 30 minutes"] <- '#FF000064'
cat.colours$colour[plot.df$Class == "Repressed at 30 minutes"] <- '#0000FF64'
cat.colours$colour <- as.factor(cat.colours$colour)
sum(plot.df$Class == "Activated at 30 minutes" & plot.df$time == 0) #37
sum(plot.df$Class == "Repressed at 30 minutes" & plot.df$time == 0) #57
```

Plot.

```{r class.source="bg-info", engine='R', eval=F, echo=T}
pdf('Normalized_counts_estrogen_response_gene_set_significant_at_30min_red_blue.pdf') 
trellis.par.set(box.umbrella = list(lty = 1, col="black", lwd=1),
                box.rectangle = list( lwd=1.0, col="black", alpha = 1.0),
                plot.symbol = list(col="black", lwd=1.0, pch ='.'))
print(
  xyplot(value ~  factor(time) | Class, group = genes, data = plot.df, type = c('l'),
         par.strip.text=list(cex=1),
         scales=list(x=list(cex=1, relation = "free", rot = 45), y =list(cex=1, relation="free")),
         aspect=1.0,
         between=list(y=0.5, x=0.5),
         ylab = list(label = 'Scaled normalized\nPRO signal', cex = 2),
         xlab = list(label = 'Time (hours)', cex = 2),
         par.settings = list(superpose.symbol = list(pch = c(16), col=c('grey20'), cex =0.5),
                             strip.background=list(col="grey80"),
                             superpose.line = list(col = as.character(cat.colours$colour), lwd=c(1), lty = c(1))),
         panel = function(x, y, ...) {
           panel.xyplot(x, y, ...)
           panel.bwplot(x, y, pch = '|', horizontal = FALSE, box.width = .5, do.out = FALSE)
           panel.loess(x, y, ..., col = "black", lwd =2.0,  span = 1/2, degree = 1, family = c("gaussian"))
           
         })
)
dev.off()
```

## ER binding intensity near dynamic ER target genes (Figure 5B)

Set up in R.

```{r class.source="bg-info", engine='R', eval=F, echo=T}
direc = "~/Library/CloudStorage/Box-Box/GuertinLab/TRPS1_timecourse_PRO_3/"
setwd(direc)

library(lattice)
library(latticeExtra)
library(DESeq2)
library(viridis)
library(tidyverse)
library(ggplot2)
library(readxl)

source('https://raw.githubusercontent.com/mjg54/znf143_pro_seq_analysis/master/docs/ZNF143_functions.R')

filter.deseq.into.bed <- function(deseq.df, gene.file) {
  x = gene.file$V4
  y = gene.file[x %in% rownames(deseq.df),]
  z = get.tss(y)
  return(z)
}

bedTools.intersect <- function(functionstring="/usr/local/anaconda3/bin/intersectBed",bed1,bed2,opt.string="-wa -wb") {
  
  options(scipen =99) # not to use scientific notation when writing out
  
  #write bed formatted dataframes to tempfile
  write.table(bed1,file= 'a.file.bed', quote=F,sep="\t",col.names=F,row.names=F)
  write.table(bed2,file= 'b.file.bed', quote=F,sep="\t",col.names=F,row.names=F)
  
  # create the command string and call the command using system()
  command1=paste('sort -k1,1 -k2,2n', 'a.file.bed', '> a.file.sorted.bed')
  cat(command1,"\n")
  try(system(command1))
  command2=paste('sort -k1,1 -k2,2n', 'b.file.bed', '> b.file.sorted.bed')
  cat(command2,"\n")
  try(system(command2))
  
  command=paste(functionstring, opt.string,"-a",'a.file.sorted.bed',"-b",'b.file.sorted.bed',">",'out.file.bed',sep=" ")
  cat(command,"\n")
  try(system(command))
  
  res=read.table('out.file.bed',header=F, comment.char='', sep = "\t")
  
  command3=paste('rm', 'a.file.bed', 'b.file.bed', 'a.file.sorted.bed', 'b.file.sorted.bed', 'out.file.bed')
  cat(command3,"\n")
  try(system(command3))
  
  colnames(res) = c(colnames(bed1), colnames(bed2))
  return(res)
}

bedTools.closest <- function(functionstring="/usr/local/anaconda3/bin/closestBed",bed1,bed2,opt.string="") {
  
  options(scipen =99) # not to use scientific notation when writing out
  
  #write bed formatted dataframes to tempfile
  write.table(bed1,file= 'a.file.bed', quote=F,sep="\t",col.names=F,row.names=F)
  write.table(bed2,file= 'b.file.bed', quote=F,sep="\t",col.names=F,row.names=F)
  
  # create the command string and call the command using system()
  command1=paste('sort -k1,1 -k2,2n', 'a.file.bed', '> a.file.sorted.bed')
  cat(command1,"\n")
  try(system(command1))
  command2=paste('sort -k1,1 -k2,2n', 'b.file.bed', '> b.file.sorted.bed')
  cat(command2,"\n")
  try(system(command2))
  
  command=paste(functionstring, opt.string,"-a",'a.file.sorted.bed',"-b",'b.file.sorted.bed',">",'out.file.bed',sep=" ")
  cat(command,"\n")
  try(system(command))
  
  res=read.table('out.file.bed',header=F, comment.char='', sep = "\t")
  
  command3=paste('rm', 'a.file.bed', 'b.file.bed', 'a.file.sorted.bed', 'b.file.sorted.bed', 'out.file.bed')
  cat(command3,"\n")
  try(system(command3))
  
  colnames(res) = c(colnames(bed1), colnames(bed2), 'dis' )
  return(res)
}

plot_cdf <- function(df.all, col.lines = c("#FF0000", "grey60", "#0000FF")) {
  ecdfplot(~log(abs(as.numeric(dis)), base = 10), groups = Class, data = df.all,
           auto.key = list(lines=TRUE, points=FALSE),
           col = col.lines,
           aspect = 1,
           scales=list(relation="free",alternating=c(1,1,1,1)),
           ylab = 'Cumulative Distribution Function',
           xlab = expression('log'[10]~" TRPS1 summit distance from ER summit"),
           between=list(y=1.0),
           type = 'a',
           xlim = c(0,7.5),
           lwd=2,
           par.settings = list(superpose.line = list(col = col.lines, lwd=3), 
                               strip.background=list(col="grey85")),
           panel = function(...) {
             panel.abline(v= 200, lty =2)
             panel.ecdfplot(...)
           })
}

#For converting gene names
gene.file = read.table("~/Library/CloudStorage/Box-Box/GuertinLab/ER_Antagonists_R/Homo_sapiens.GRCh38.104.bed", sep = '\t', header = FALSE)
`%notin%` <- Negate(`%in%`)
gene.file = gene.file[gene.file$V5 %notin% c("havana", "havana_tagene", "ensembl_havana"),]
gene.symbol = gene.file[,c(4,5)]
colnames(gene.symbol) = c("gene", "symbol")
```

Get read depth.

```{r class.source="bg-info", engine='R', eval=F, echo=T}
complexity_estimate <- read.table("~/Library/CloudStorage/Box-Box/GuertinLab/ChIP/logs/230322_complexity_estimate.txt", header = T)
name = sapply(strsplit(complexity_estimate$name, "Clone28_"), "[", 2)
complexity_estimate = t(complexity_estimate$unique_reads)
colnames(complexity_estimate) = name
complexity_estimate = complexity_estimate[,-grep("HA", colnames(complexity_estimate))]
```

Read in the counts table and change the column names.

```{r class.source="bg-info", engine='R', eval=F, echo=T}
x <- read.table("Combined_ER_peak_counts.txt", sep = '\t', header = TRUE)
rownames(x) = paste0(x[,1], ":", x[,2], "-", x[,3])
peak_name = x[,4]
peak_qvalue = x[,5]
x = x[,-c(1:5)]
colnames(x) = sapply(strsplit(sapply(strsplit(colnames(x), "Clone28_"), "[", 2), "_ER"), "[", 1)
```

Subtract the read depth normalized background signal.


```{r class.source="bg-info", engine='R', eval=F, echo=T}
background <- sweep(x[,grep("IgG", colnames(x))], 2, complexity_estimate[grep("IgG", names(complexity_estimate))], FUN = "/")
background = rowMeans(background)
background = cbind.data.frame(background, background, background, background, background, background, background, background)
background <- sweep(as.data.frame(background), 2, complexity_estimate[grep("ER", names(complexity_estimate))], FUN = "*")
background = round(background, digits = 0)

x = x[,grep("ER", colnames(x))] - background
x[x < 0] = 0
```

Run DESeq2.

```{r class.source="bg-info", engine='R', eval=F, echo=T}
treatment = factor(sapply(strsplit(colnames(x), '_'), '[', 2), levels = c("DMSO", "dTAG"))
rep = factor(sapply(strsplit(colnames(x), 'rep'), '[', 2))
deseq.df = DESeqDataSetFromMatrix(x, cbind.data.frame(treatment, rep), ~ treatment)
factors <- read.table("ER_sizeFactor.txt")
size_factors = factors$V2
names(size_factors) = factors$V1
sizeFactors(deseq.df) <- size_factors
deseq.df = DESeq(deseq.df)
save(deseq.df, file = "deseq.df.ER.Rdata")
load("deseq.df.ER.Rdata")
```

Get normalized counts for each condition.

```{r class.source="bg-info", engine='R', eval=F, echo=T}
counts = as.data.frame(counts(deseq.df[peak_qvalue > 200,], normalized = TRUE))
counts$chr = sapply(strsplit(rownames(counts), ":"), "[", 1)
coord = sapply(strsplit(rownames(counts), ":"), "[", 2)
counts$start = sapply(strsplit(coord, "-"), "[", 1)
counts$end = sapply(strsplit(coord, "-"), "[", 2)
counts$DMSO = rowMeans(counts[,grep("DMSO", colnames(counts))])
counts$dTAG = rowMeans(counts[,grep("dTAG", colnames(counts))])
counts = counts[,9:13]
rownames(counts) = NULL
```

Get dynamic ER target genes.

```{r class.source="bg-info", engine='R', eval=F, echo=T}
load("deseq.df_all_reads.RData")
res.deseq = results(deseq.df, contrast = c("time", "0.5hour", "0hour"))
estrogen_response_genes = read.table("~/Library/CloudStorage/Box-Box/GuertinLab/ER_Antagonists_R/estrogen_activated_gene_names.txt", header = FALSE)$V1
estrogen_response_genes = gene.symbol$gene[gene.symbol$symbol %in% estrogen_response_genes]
res.deseq = res.deseq[rownames(res.deseq) %in% estrogen_response_genes,]
```

Set up a window of 100kbp around each transcription start site.

```{r class.source="bg-info", engine='R', eval=F, echo=T}
tss.df = filter.deseq.into.bed(res.deseq, gene.file)
colnames(tss.df) = c("tss.chr", "tss.start", "tss.end", "gene", "symbol", "strand")
tss.df = merge.data.frame(tss.df, res.deseq, by.x = "gene", by.y = "row.names")
tss.df[,1:4] = tss.df[,c(2:4,1)]
colnames(tss.df)[1:4] = colnames(tss.df)[c(2:4,1)]
tss.df$tss.start = tss.df$tss.start - 100000
tss.df$tss.end = tss.df$tss.end + 100000
```

Generate transcripts per million.

```{r class.source="bg-info", engine='R', eval=F, echo=T}
counts.mat = counts(deseq.df, normalized = F)
counts.mat = merge(counts.mat, gene.file, by.x = 0, by.y = "V4")
rownames(counts.mat) = counts.mat$Row.names
gene.length = counts.mat$V3 - counts.mat$V2
gene.full.length = gene.length
x <- counts.mat[,grep("T47D", colnames(counts.mat))] / gene.length
tpm.mat <- as.data.frame(t( t(x) * 1e6 / colSums(x) ))
tpm.mat$DMSO_TPM = log(rowMeans(tpm.mat[,grep("0hour", colnames(tpm.mat))]), 10)
tpm.mat$dTAG_TPM = log(rowMeans(tpm.mat[,grep("0.5hour", colnames(tpm.mat))]), 10)
tpm.mat$gene_length = gene.full.length
tss.df = merge(tss.df, tpm.mat[, c("DMSO_TPM", "dTAG_TPM", "gene_length")], by.x = "gene", by.y = 0)
tss.df[,1:4] = tss.df[,c(2:4,1)]
colnames(tss.df)[1:4] = colnames(tss.df)[c(2:4,1)]
```

Match unchanged genes based on expression.

```{r class.source="bg-info", engine='R', eval=F, echo=T}
tss.df$Match = "Controls"
tss.df$Class = "Other Genes"
tss.df$Class[!is.na(tss.df$padj) & tss.df$padj < 0.1 & tss.df$log2FoldChange > 0] = "Activated Genes"
tss.df$Class[!is.na(tss.df$padj) & tss.df$padj < 0.1 & tss.df$log2FoldChange < 0] = "Repressed Genes"
tss.df$Match[tss.df$Class == "Activated Genes"] = "Cases"
tss.df$Match = relevel(factor(tss.df$Match), ref = "Controls")

tpm.mat$DMSO_TPM = log(tpm.mat$DMSO_TPM, 10)
tpm.mat$dTAG_TPM = log(tpm.mat$dTAG_TPM, 10)
out = matchit(Match ~ DMSO_TPM, data = tss.df[tss.df$Class != "Repressed Genes",], method = "optimal", ratio = 1)
out2 = matchit(Match ~ DMSO_TPM, data = tss.df[tss.df$Class != "Other Genes",], method = "optimal", ratio = 1)
tss.df = tss.df[tss.df$Match == "Cases" | rownames(tss.df) %in% out$match.matrix | rownames(tss.df) %in% out2$match.matrix,]
rownames(tss.df) = NULL
```

Get ER peaks near the genes.

```{r class.source="bg-info", engine='R', eval=F, echo=T}
peaks_near_genes = bedTools.intersect(bed1 = tss.df, bed2 = counts, opt.string = "-wa -wb")
peaks_near_genes$Class = factor(peaks_near_genes$Class, levels = c("Activated Genes", "Other Genes", "Repressed Genes"))
peaks_near_genes = peaks_near_genes[,c(1:22)]
```

Plot.

```{r class.source="bg-info", engine='R', eval=F, echo=T}
pdf("ER_q200_ChIP_intensity_near_dynamic_ER_target_genes_100kb.pdf", width = 7, height = 3.5)
ggplot(data = peaks_near_genes, aes(x = Class, y = log(dTAG/DMSO, base = 2), color = Class),) +
  theme(legend.position = "none") +
  geom_violin() +
  geom_boxplot(width=.1, outlier.shape = NA) +
  geom_jitter(size = .01) +
  geom_hline(yintercept = 0, linetype="dashed") +
  scale_color_manual(values = c("red", "grey60", "blue")) +
  xlab(NULL) +
  ylab(expression("log"[2]~"(fold change in ER binding intensity)")) +
  xlab("Genes class defined by change in expression upon TRPS1 depletion") +
  ggtitle("Change in ER binding intensity in peaks near ER target genes") +
  theme_bw() +
  theme(legend.position="none", plot.title = element_text(hjust = 0.5))
dev.off()
```

T-tests.

```{r class.source="bg-info", engine='R', eval=F, echo=T}
Activated = peaks_near_genes[peaks_near_genes$Class == "Activated Genes",]
t.test(log(Activated$dTAG), log(Activated$DMSO), paired = T) #0.000000000000002274
Unchanged = peaks_near_genes[peaks_near_genes$Class == "Other Genes",]
t.test(log(Unchanged$dTAG), log(Unchanged$DMSO), paired = T) #0.3518
Repressed = peaks_near_genes[peaks_near_genes$Class == "Repressed Genes",]
t.test(log(Repressed$dTAG), log(Repressed$DMSO), paired = T) #0.000003224
```

## ER binding intensity by TRPS1 proximity (Figure 5C)

Get the distance from each ER peak summit to the nearest TRPS1 peak summit.

```{r class.source="bg-info", engine='R', eval=F, echo=T}
q = 30
peaks = read.table("~/Library/CloudStorage/Box-Box/GuertinLab/ChIP/results/macs2/HA_DMSO_vs_dTAG_summits.bed", sep = "\t")
x <- read.table("Combined_HA_DMSO_vs_dTAG_peak_counts.txt", sep = '\t', header = TRUE)
peak_qvalue = x[,5]
peaks = bedTools.closest(bed1 = counts, bed2 = peaks[peak_qvalue > q,], opt.string = "-d")
peaks$status[!is.na(peaks$padj) & peaks$padj < 0.1 & peaks$log2FoldChange > 0] = "Increasing"
peaks$status[!is.na(peaks$padj) & peaks$padj < 0.1 & peaks$log2FoldChange < 0] = "Decreasing"
peaks$status[!is.na(peaks$padj) & peaks$padj >= 0.1] = "Not significantly changing"
peaks$status = factor(peaks$status, levels = c("Increasing", "Not significantly changing", "Decreasing"))
colnames(peaks)[colnames(peaks) == "V5"] = "q_value"
```

Bin the ER peaks by proximity to TRPS1 peaks.

```{r class.source="bg-info", engine='R', eval=F, echo=T}
peaks$Class = NULL
peaks$Class[peaks$dis < 200] = "< 200bp"
peaks$Class[peaks$dis >= 200 & peaks$dis <= 500] = "200 - 500bp"
peaks$Class[peaks$dis > 500] = "> 500bp"
peaks$Class = factor(peaks$Class, levels = c("< 200bp", "200 - 500bp", "> 500bp"))
```

Plot.

```{r class.source="bg-info", engine='R', eval=F, echo=T}
pdf("ER_ChIP_intensity_by_binned_HA_proximity.pdf", width = 7, height = 3.5)
ggplot(data = peaks[peaks$Class %in% levels(peaks$Class),], aes(x = Class, y = log(dTAG/DMSO, base = 2), color = Class),) +
  theme(legend.position = "none") +
  geom_hline(yintercept = 0, linetype="dashed") +
  geom_violin() +
  geom_boxplot(width=.1, outlier.shape = NA) +
  geom_jitter(size = .01) +
  geom_hline(yintercept = 0, linetype="dashed") +
  scale_color_manual(values = c("#FF0000", "grey60", "#0000FF")) +
  xlab("Distance to nearest TRPS1 peak") +
  ylab(expression("log"[2]~"(fold change in ER binding intensity)")) +
  ggtitle("Change in ER binding intensity by proximity to TRPS1") +
  theme_bw() +
  theme(legend.position="none", plot.title = element_text(hjust = 0.5))
dev.off()
```

T-tests.

```{r class.source="bg-info", engine='R', eval=F, echo=T}
Close = peaks[peaks$Class == "< 200bp",]
t.test(log(Close$dTAG), log(Close$DMSO), paired = T) #<0.00000000000000022
Intermediate = peaks[peaks$Class == "200 - 500bp",]
t.test(log(Intermediate$dTAG), log(Intermediate$DMSO), paired = T) #0.4901
Far = peaks[peaks$Class == "> 500bp",]
t.test(log(Far$dTAG), log(Far$DMSO), paired = T) #0.00001017
```

# Outcomes associations

## MA plot of gene expression at 24 hours dTAG vs. DMSO (Figure 6A)

Set up in R.

```{r class.source="bg-info", engine='R', eval=F, echo=T}
direc = "~/Library/CloudStorage/Box-Box/GuertinLab/TRPS1_timecourse_PRO_3/"
setwd(direc)

library(lattice)
library(DESeq2)
library(viridis)
library(tidyverse)
library(latticeExtra)
library(msigdbr)
library(clusterProfiler)
library(fgsea)
library(enrichplot)
library(clusterProfiler)
library(DEGreport)
library(dplyr)
library(tidyr)
library(ggplot2)
library(data.table)

source('https://raw.githubusercontent.com/mjg54/znf143_pro_seq_analysis/master/docs/ZNF143_functions.R')

filter.deseq.into.bed <- function(deseq.df, gene.file, cat = 'R1881 Activated') {
  deseq.df = deseq.df[deseq.df$status == cat,]
  #print(dim(deseq.df))
  #scientific notation was messing this up occasionally
  x = gene.file$V4
  #print(length(x))
  y = gene.file[x %in% rownames(deseq.df),]
  #print(dim(y))
  z = get.tss(y)
  #print(dim(z))
  return(z)
}

#bedTools.closest <- function(functionstring="/anaconda3/bin/closestBed",bed1,bed2,opt.string="") {
bedTools.closest <- function(functionstring="/usr/local/anaconda3/bin/closestBed",bed1,bed2,opt.string="") {
  
  options(scipen =99) # not to use scientific notation when writing out
  
  #write bed formatted dataframes to tempfile
  write.table(bed1,file= 'a.file.bed', quote=F,sep="\t",col.names=F,row.names=F)
  write.table(bed2,file= 'b.file.bed', quote=F,sep="\t",col.names=F,row.names=F)
  
  # create the command string and call the command using system()
  command1=paste('sort -k1,1 -k2,2n', 'a.file.bed', '> a.file.sorted.bed')
  cat(command1,"\n")
  try(system(command1))
  command2=paste('sort -k1,1 -k2,2n', 'b.file.bed', '> b.file.sorted.bed')
  cat(command2,"\n")
  try(system(command2))
  
  command=paste(functionstring, opt.string,"-a",'a.file.sorted.bed',"-b",'b.file.sorted.bed',">",'out.file.bed',sep=" ")
  cat(command,"\n")
  try(system(command))
  
  res=read.table('out.file.bed',header=F, comment.char='')
  
  command3=paste('rm', 'a.file.bed', 'b.file.bed', 'a.file.sorted.bed', 'b.file.sorted.bed', 'out.file.bed')
  cat(command3,"\n")
  try(system(command3))
  
  colnames(res) = c(colnames(bed1), colnames(bed2)[1:ncol(bed2)], 'dis' )
  return(res)
}

#color scheme
col.lines = c("red", "blue", "grey60")

#For converting gene names
gene.file = read.table("~/Library/CloudStorage/Box-Box/GuertinLab/ER_Antagonists_R/Homo_sapiens.GRCh38.104.bed", sep = '\t', header = FALSE)
`%notin%` <- Negate(`%in%`)
gene.file = gene.file[gene.file$V5 %notin% c("havana", "havana_tagene", "ensembl_havana"),]
gene.symbol = gene.file[,c(4,5)]
colnames(gene.symbol) = c("gene", "symbol")
```

Identify differentially expressed genes at 24 hours, shrinking the fold changes.

```{r class.source="bg-info", engine='R', eval=F, echo=T}
load("deseq.df_all_reads.RData")
i = "24hour"
res.deseq = results(deseq.df, contrast = c("time", i, "0hour"))
res.deseq = res.deseq[rownames(res.deseq) %in% gene.symbol$gene,]
res.deseq = merge(as.data.frame(res.deseq), gene.symbol, by.x = 0, by.y = "gene")

res.deseq.shrink <- lfcShrink(deseq.df, coef = "time_24hour_vs_0hour", type="ashr")
res.deseq.shrink = res.deseq.shrink[rownames(res.deseq.shrink) %in% gene.symbol$gene,]
sum(res.deseq.shrink$padj < 0.1 & !is.na(res.deseq.shrink$padj))

df.deseq.effects.lattice = res.deseq.shrink
df.deseq.effects.lattice$status = "Other"
df.deseq.effects.lattice$status[res.deseq.shrink$padj < 0.1 & !is.na(res.deseq.shrink$padj) & res.deseq.shrink$log2FoldChange > 0] = "Activated"
df.deseq.effects.lattice$status[res.deseq.shrink$padj < 0.1 & !is.na(res.deseq.shrink$padj) & res.deseq.shrink$log2FoldChange < 0] = "Repressed"
df.deseq.effects.lattice$status = factor(df.deseq.effects.lattice$status, levels = c("Other", "Activated", "Repressed"))
```

Plot.

```{r class.source="bg-info", engine='R', eval=F, echo=T}
pdf("MA_PRO_24hour_ashr_for_figure.pdf", width = 7, height = 3.5)
ggplot(as.data.frame(df.deseq.effects.lattice) %>% arrange(status), aes(x = log(baseMean, 10), y = log2FoldChange, color = status)) +
  geom_point() +
  scale_color_manual(values = c("grey60", "red", "blue")) +
  geom_hline(yintercept = 0, linetype="dashed") +
  ylim(-1, 1) +
  xlim(0, 5) +
  ylab(expression("Shrunken log"[2]~"(fold change in PRO signal)")) +
  xlab(expression("log"[10]~"(mean of normalized intensity)")) +
  ggtitle("Change in expression 24 hours after TRPS1 depletion") +
  theme_bw() +
  theme(plot.title = element_text(hjust = 0.5)) +
  labs(color=NULL)
dev.off()
```

## 24 hour gene set enrichment analysis (Figure 6B)

Rank genes based on shrunken fold change.

```{r class.source="bg-info", engine='R', eval=F, echo=T}
original_gene_list <- res.deseq.shrink$log2FoldChange
names(original_gene_list) <- rownames(res.deseq.shrink)
gene_list<-na.omit(original_gene_list)
gene_list = sort(gene_list, decreasing = TRUE)

h_gene_sets = msigdbr(species = "Homo sapiens", category = "H")
msigdbr_list = split(x = h_gene_sets$ensembl_gene, f = h_gene_sets$gs_name)
set.seed(0)
fgseaRes <- fgsea(msigdbr_list, gene_list, eps = 0)

fgseaResTidy <- fgseaRes %>%
  as_tibble() %>%
  arrange(desc(NES))

print(fgseaResTidy[fgseaResTidy$padj < 0.1,], n = 100)
gse_top = fgseaResTidy[fgseaResTidy$padj < 0.1,]
```

Plot.

```{r class.source="bg-info", engine='R', eval=F, echo=T}
#padj 2.45e-19
pdf("Mountain_plot_24hour_E2F_targets.pdf", height = 5)
plotEnrichment(msigdbr_list[["HALLMARK_E2F_TARGETS"]], gene_list) + 
  ylim(-.9, .1) + 
  labs(title="Hallmark E2F Targets")
dev.off()
```

## Growth curves (Figure 6C)

Set up in R.

```{r class.source="bg-info", engine='R', eval=F, echo=T}
direc = "~/Library/CloudStorage/Box-Box/GuertinLab/Cell_Counts/"
setwd(direc)

library(readxl)
library(tidyr)
library(plyr)
library(dplyr)
library(ggplot2)
library(viridis)

summarySE <- function(data=NULL, measurevar, groupvars=NULL, na.rm=FALSE, conf.interval=.95, .drop=TRUE) {
  # New version of length which can handle NA's: if na.rm==T, don't count them
  length2 <- function (x, na.rm=FALSE) {
    if (na.rm) sum(!is.na(x))
    else       length(x)
  }
  # This does the summary. For each group's data frame, return a vector with
  # N, mean, and sd
  datac <- ddply(data, groupvars, .drop=.drop,
                 .fun = function(xx, col) {
                   c(N    = length2(xx[[col]], na.rm=na.rm),
                     mean = mean   (xx[[col]], na.rm=na.rm),
                     sd   = sd     (xx[[col]], na.rm=na.rm)
                   )
                 },
                 measurevar
  )
  # Rename the "mean" column    
  datac <- plyr::rename(datac, c("mean" = measurevar))
  datac$se <- datac$sd / sqrt(datac$N)  # Calculate standard error of the mean
  # Confidence interval multiplier for standard error
  # Calculate t-statistic for confidence interval: 
  # e.g., if conf.interval is .95, use .975 (above/below), and use df=N-1
  ciMult <- qt(conf.interval/2 + .5, datac$N-1)
  datac$ci <- datac$se * ciMult
  return(datac)
}
```

Read in the counts data.

```{r class.source="bg-info", engine='R', eval=F, echo=T}
Cell_Counts <- read_excel("220831_dTAG_TRPS1_reps_3_to_6.xlsx")
```

Convert to cells/well.

```{r class.source="bg-info", engine='R', eval=F, echo=T}
Dilution_factor <- 10000*Cell_Counts$mL/9
Cell_Counts <- Cell_Counts[,-6]
Cell_Counts[,3:5] = Cell_Counts[,3:5]*Dilution_factor
```

Average the technical replicates.

```{r class.source="bg-info", engine='R', eval=F, echo=T}
Cell_Counts <- pivot_longer(Cell_Counts, colnames(Cell_Counts)[3:5], names_to = "Condition", values_to = "Count")
Cell_Counts <- summarySE(Cell_Counts, measurevar="Count", groupvars=c("Condition", "Day", "Rep"))
Cell_Counts <- Cell_Counts[,c(1,2,3,5)]
Cell_Counts <- na.omit(Cell_Counts)
```

Calculate mean and standard error for the biological replicates.

```{r class.source="bg-info", engine='R', eval=F, echo=T}
Summary <- summarySE(Cell_Counts, measurevar="Count", groupvars=c("Condition", "Day"))
```

Fit a linear model to the data with and without an interaction term for the effect of dTAG.

```{r class.source="bg-info", engine='R', eval=F, echo=T}
pd <- position_dodge(0.1)
ylim <- c(0, 500000)
fit = lm(log(Count, base = 2) ~ Day*Condition, data = Cell_Counts[Cell_Counts$Condition != "Untreated",])
fit_no_interaction = lm(log(Count, base = 2) ~ Day + Condition, data = Cell_Counts[Cell_Counts$Condition != "Untreated",])
anova(fit_no_interaction, fit) # p = 1.01e-05
predict = predict(fit, interval = "confidence")
Cell_Counts$lwr[Cell_Counts$Condition != "Untreated"] = predict[,2]
Cell_Counts$upr[Cell_Counts$Condition != "Untreated"] = predict[,3]
```

Plot.

```{r class.source="bg-info", engine='R', eval=F, echo=T}
pdf("dTAG_TRPS1_reps3_to_6_curve_fit_confidence.pdf", width = 14)
ggplot(Cell_Counts, aes(x=Day, y=Count, colour=Condition, fill = Condition)) + 
  geom_point(data=Cell_Counts, size=3, shape=21) +
  stat_function(fun=function(x) 2^(as.numeric(fit$coefficients[1]) + as.numeric(fit$coefficients[2])*x), color = "Black") +
  stat_function(fun=function(x) 2^(as.numeric(fit$coefficients[1] + fit$coefficients[3]) + as.numeric(fit$coefficients[2] + fit$coefficients[4])*x), color = "Red") +
  geom_errorbar(aes(ymin=2^lwr, ymax=2^upr), width=.1) +
  scale_colour_manual(values = c("Black", "Red", "Grey"), labels = c("DMSO", "dTAG", "Untreated")) +   
  scale_fill_manual(values = c("Black", "Red", "Grey"), labels = c("DMSO", "dTAG", "Untreated")) +    
  scale_x_continuous(breaks = c(0, 3, 7, 10, 14), minor_breaks = seq(0,14,1)) +
  ylab("Cell Number") +
  theme_bw() +
  theme(legend.justification = "center",
        legend.position = c(0.2, 0.7),
        legend.title = element_blank(),
        plot.title = element_text(hjust = 0.5),
        legend.text = element_text(size=24),
        axis.text=element_text(size=12),
        axis.title=element_text(size=24,face="bold"))      
dev.off()
```

## Plot example patient with high TRPS1 activity score (Figure 6D)

Set up in R.

```{r class.source="bg-info", engine='R', eval=F, echo=T}
direc = "~/Library/CloudStorage/Box-Box/GuertinLab/TRPS1_timecourse_PRO_3/"
setwd(direc)

library(DESeq2)
library(RTN)
library(RTNsurvival)
library(pheatmap)
library(Fletcher2013b)

#For converting gene names
gene.file = read.table("~/Library/CloudStorage/Box-Box/GuertinLab/ER_Antagonists_R/Homo_sapiens.GRCh38.104.bed", sep = '\t', header = FALSE)
`%notin%` <- Negate(`%in%`)
gene.file = gene.file[gene.file$V5 %notin% c("havana", "havana_tagene", "ensembl_havana"),]
gene.symbol = gene.file[,c(4,5)]
colnames(gene.symbol) = c("gene", "symbol")
```

Identify primary TRPS1-reponsive genes.

```{r class.source="bg-info", engine='R', eval=F, echo=T}
load("deseq.df_all_reads.RData")
i = "0.5hour"
res.deseq = results(deseq.df, contrast = c("time", i, "0hour"))
res.deseq = res.deseq[rownames(res.deseq) %in% gene.symbol$gene,]
res.deseq = merge(as.data.frame(res.deseq), gene.symbol, by.x = 0, by.y = "gene")

activated = res.deseq$symbol[res.deseq$padj < 0.1 & !is.na(res.deseq$padj) & res.deseq$log2FoldChange > 0] 
repressed = res.deseq$symbol[res.deseq$padj < 0.1 & !is.na(res.deseq$padj) & res.deseq$log2FoldChange < 0] 
```

Define the TRPS1 regulon based on our own primary gene set.

```{r class.source="bg-info", engine='R', eval=F, echo=T}
data("rtni1st")
TRPS1 = rtni1st@regulatoryElements["TRPS1"]
ILMN_SYMBOL = rtni1st@rowAnnotation
rtni1st@results$tn.dpi[,TRPS1] <- 0
rtni1st@results$tn.dpi[,TRPS1][names(rtni1st@results$tn.dpi[,TRPS1]) %in% 
                                 ILMN_SYMBOL$PROBEID[ILMN_SYMBOL$SYMBOL %in% activated]] <- -1
rtni1st@results$tn.dpi[,TRPS1][names(rtni1st@results$tn.dpi[,TRPS1]) %in% 
                                 ILMN_SYMBOL$PROBEID[ILMN_SYMBOL$SYMBOL %in% repressed]] <- 1

tns1st <-tni2tnsPreprocess(tni = rtni1st, regulatoryElements = c("TRPS1"), time = "time", event = "event", keycovar =c("Age","Grade"))
tns1st <-tnsGSEA2(tns1st)

data("rtni2nd")
TRPS1 = rtni2nd@regulatoryElements["TRPS1"]
ILMN_SYMBOL = rtni2nd@rowAnnotation
rtni2nd@results$tn.dpi[,TRPS1] <- 0
rtni2nd@results$tn.dpi[,TRPS1][names(rtni2nd@results$tn.dpi[,TRPS1]) %in% 
                                 ILMN_SYMBOL$PROBEID[ILMN_SYMBOL$SYMBOL %in% activated]] <- -1
rtni2nd@results$tn.dpi[,TRPS1][names(rtni2nd@results$tn.dpi[,TRPS1]) %in% 
                                 ILMN_SYMBOL$PROBEID[ILMN_SYMBOL$SYMBOL %in% repressed]] <- 1

tns2nd <-tni2tnsPreprocess(tni = rtni2nd, regulatoryElements = c("TRPS1"), time = "time", event = "event", keycovar =c("Age", "Grade"))
tns2nd <-tnsGSEA2(tns2nd)
```

Merge the two halves of the cohort.

```{r class.source="bg-info", engine='R', eval=F, echo=T}
tns_both = tns1st
tns_both@survivalData <- rbind(tns1st@survivalData[,-ncol(tns1st@survivalData)], tns2nd@survivalData)
tns_both@results$regulonActivity$differential = rbind(tns1st@results$regulonActivity$differential,
                                                      tns2nd@results$regulonActivity$differential)
tns_both@results$regulonActivity$positive = rbind(tns1st@results$regulonActivity$positive,
                                                  tns2nd@results$regulonActivity$positive)
tns_both@results$regulonActivity$negative = rbind(tns1st@results$regulonActivity$negative,
                                                  tns2nd@results$regulonActivity$negative)
tns_both@results$regulonActivity$status = rbind(tns1st@results$regulonActivity$status,
                                                tns2nd@results$regulonActivity$status)
```

Get regulon activity and sample attributes.

```{r class.source="bg-info", engine='R', eval=F, echo=T}
regact_gsea <-tnsGet(tns_both, "regulonActivity")$dif
sdata <-tnsGet(tns_both, "survivalData")
attribs <-c("ER+", "ER-","LumA","LumB","Basal","Her2","Normal")
```

Run KM and Cox analysis.

```{r class.source="bg-info", engine='R', eval=F, echo=T}
tns_both <-tnsKM(tns_both)
tns_both <-tnsCox(tns_both)
```

Identify the patient with the highest TRPS1 activity score.

```{r class.source="bg-info", engine='R', eval=F, echo=T}
max = rownames(tns_both@results$regulonActivity$differential)[tns_both@results$regulonActivity$differential == max(tns_both@results$regulonActivity$differential)]
```

Plot.

```{r class.source="bg-info", engine='R', eval=F, echo=T}
pdf("RTNsurvival_GSEA2_TRPS1_high_regulon_merged_METABRIC_30minutes_FDR_0.1.pdf", height = 3, width = 3)
tnsPlotGSEA2(tns_both, max, regs = "TRPS1")
dev.off()
```

## Plot distribution of TRPS1 activity scores and Kaplan-Meier curves binned by TRPS1 activity score(Figure 6E,F)

Plot.

```{r class.source="bg-info", engine='R', eval=F, echo=T}
#Logrank p-value 4.99e-4
pdf("RTNsurvival_TRPS1_regulon_merged_METABRIC_after_GSEA_30minutes_FDR_0.1_no_endpoint.pdf", height = 3, width = 6)
tnsPlotKM(tns_both, regs = "TRPS1", attribs = attribs, panelWidths=c(3,1,4), width = 6)
dev.off()
```

## Break down patient outcomes data by ER-positivity and by intrinsic subtype (Figure S10)

Here we repeat the above analyses but only plotting subsets of the patients.

```{r class.source="bg-info", engine='R', eval=F, echo=T}
#Just ER positive
data("rtni1st")
TRPS1 = rtni1st@regulatoryElements["TRPS1"]
ILMN_SYMBOL = rtni1st@rowAnnotation
rtni1st@results$tn.dpi[,TRPS1] <- 0
rtni1st@results$tn.dpi[,TRPS1][names(rtni1st@results$tn.dpi[,TRPS1]) %in% 
                                 ILMN_SYMBOL$PROBEID[ILMN_SYMBOL$SYMBOL %in% activated]] <- -1
rtni1st@results$tn.dpi[,TRPS1][names(rtni1st@results$tn.dpi[,TRPS1]) %in% 
                                 ILMN_SYMBOL$PROBEID[ILMN_SYMBOL$SYMBOL %in% repressed]] <- 1

tns1st <-tni2tnsPreprocess(tni = rtni1st, regulatoryElements = c("TRPS1"), time = "time", 
                           event = "event", keycovar =c("Age","Grade")
                           , excludeAttribs = "ER-"
                           )
tns1st <-tnsGSEA2(tns1st)

data("rtni2nd")
TRPS1 = rtni2nd@regulatoryElements["TRPS1"]
ILMN_SYMBOL = rtni2nd@rowAnnotation
rtni2nd@results$tn.dpi[,TRPS1] <- 0
rtni2nd@results$tn.dpi[,TRPS1][names(rtni2nd@results$tn.dpi[,TRPS1]) %in% 
                                 ILMN_SYMBOL$PROBEID[ILMN_SYMBOL$SYMBOL %in% activated]] <- -1
rtni2nd@results$tn.dpi[,TRPS1][names(rtni2nd@results$tn.dpi[,TRPS1]) %in% 
                                 ILMN_SYMBOL$PROBEID[ILMN_SYMBOL$SYMBOL %in% repressed]] <- 1

tns2nd <-tni2tnsPreprocess(tni = rtni2nd, regulatoryElements = c("TRPS1"), time = "time", 
                           event = "event", keycovar =c("Age", "Grade")
                           , excludeAttribs = "ER-"
                           )
tns2nd <-tnsGSEA2(tns2nd)

#Merge
tns_both = tns1st
tns_both@survivalData <- rbind(tns1st@survivalData[,-ncol(tns1st@survivalData)], tns2nd@survivalData)
tns_both@results$regulonActivity$differential = rbind(tns1st@results$regulonActivity$differential,
                                                      tns2nd@results$regulonActivity$differential)
tns_both@results$regulonActivity$positive = rbind(tns1st@results$regulonActivity$positive,
                                                  tns2nd@results$regulonActivity$positive)
tns_both@results$regulonActivity$negative = rbind(tns1st@results$regulonActivity$negative,
                                                  tns2nd@results$regulonActivity$negative)
tns_both@results$regulonActivity$status = rbind(tns1st@results$regulonActivity$status,
                                                tns2nd@results$regulonActivity$status)

#Get regulon activity and sample attributes
regact_gsea <-tnsGet(tns_both, "regulonActivity")$dif
sdata <-tnsGet(tns_both, "survivalData")
attribs <-c("ER+", "ER-","LumA","LumB","Basal","Her2","Normal")

#Run KM and Cox analysis
tns_both <-tnsKM(tns_both)
tns_both <-tnsCox(tns_both)

#Logrank p-value 3.86e-6
pdf("RTNsurvival_TRPS1_regulon_merged_METABRIC_after_GSEA_30minutes_FDR_0.1_no_endpoint_just_ER_positive.pdf", height = 3, width = 6)
tnsPlotKM(tns_both, regs = "TRPS1", attribs = attribs, panelWidths=c(3,1,4), width = 6)
dev.off()




#Just ER negative
tns1st <-tni2tnsPreprocess(tni = rtni1st, regulatoryElements = c("TRPS1"), time = "time", 
                           event = "event", keycovar =c("Age","Grade"), 
                           excludeAttribs = "ER+")
tns1st <-tnsGSEA2(tns1st)

tns2nd <-tni2tnsPreprocess(tni = rtni2nd, regulatoryElements = c("TRPS1"), time = "time", 
                           event = "event", keycovar =c("Age","Grade"), 
                           excludeAttribs = "ER+")
tns2nd <-tnsGSEA2(tns2nd)

#Merge
tns_both = tns1st
tns_both@survivalData <- rbind(tns1st@survivalData[,-ncol(tns1st@survivalData)], tns2nd@survivalData)
tns_both@results$regulonActivity$differential = rbind(tns1st@results$regulonActivity$differential,
                                                      tns2nd@results$regulonActivity$differential)
tns_both@results$regulonActivity$positive = rbind(tns1st@results$regulonActivity$positive,
                                                  tns2nd@results$regulonActivity$positive)
tns_both@results$regulonActivity$negative = rbind(tns1st@results$regulonActivity$negative,
                                                  tns2nd@results$regulonActivity$negative)
tns_both@results$regulonActivity$status = rbind(tns1st@results$regulonActivity$status,
                                                tns2nd@results$regulonActivity$status)

#Get regulon activity and sample attributes
regact_gsea <-tnsGet(tns_both, "regulonActivity")$dif
sdata <-tnsGet(tns_both, "survivalData")
attribs <-c("ER+", "ER-","LumA","LumB","Basal","Her2","Normal")

#Run KM and Cox analysis
tns_both <-tnsKM(tns_both)
tns_both <-tnsCox(tns_both)

#Logrank p-value 
pdf("RTNsurvival_TRPS1_regulon_merged_METABRIC_after_GSEA_30minutes_FDR_0.1_no_endpoint_just_ER_negative.pdf", height = 3, width = 6)
tnsPlotKM(tns_both, regs = "TRPS1", attribs = attribs, panelWidths=c(3,1,4), width = 6)
dev.off()




#Just Basal
tns1st <-tni2tnsPreprocess(tni = rtni1st, regulatoryElements = c("TRPS1"), time = "time", 
                           event = "event", keycovar =c("Age","Grade"), 
                           excludeAttribs = c("LumA", "LumB", "Her2", "Normal"))
tns1st <-tnsGSEA2(tns1st)

tns2nd <-tni2tnsPreprocess(tni = rtni2nd, regulatoryElements = c("TRPS1"), time = "time", 
                           event = "event", keycovar =c("Age","Grade"), 
                           excludeAttribs = c("LumA", "LumB", "Her2", "Normal"))
tns2nd <-tnsGSEA2(tns2nd)

#Merge
tns_both = tns1st
tns_both@survivalData <- rbind(tns1st@survivalData[,-ncol(tns1st@survivalData)], tns2nd@survivalData)
tns_both@results$regulonActivity$differential = rbind(tns1st@results$regulonActivity$differential,
                                                      tns2nd@results$regulonActivity$differential)
tns_both@results$regulonActivity$positive = rbind(tns1st@results$regulonActivity$positive,
                                                  tns2nd@results$regulonActivity$positive)
tns_both@results$regulonActivity$negative = rbind(tns1st@results$regulonActivity$negative,
                                                  tns2nd@results$regulonActivity$negative)
tns_both@results$regulonActivity$status = rbind(tns1st@results$regulonActivity$status,
                                                tns2nd@results$regulonActivity$status)

#Get regulon activity and sample attributes
regact_gsea <-tnsGet(tns_both, "regulonActivity")$dif
sdata <-tnsGet(tns_both, "survivalData")
attribs <-c("ER+", "ER-","LumA","LumB","Basal","Her2","Normal")

#Run KM and Cox analysis
tns_both <-tnsKM(tns_both)
tns_both <-tnsCox(tns_both)

#Logrank p-value 
pdf("RTNsurvival_TRPS1_regulon_merged_METABRIC_after_GSEA_30minutes_FDR_0.1_no_endpoint_just_Basal.pdf", height = 3, width = 6)
tnsPlotKM(tns_both, regs = "TRPS1", attribs = attribs, panelWidths=c(3,1,4), width = 6)
dev.off()



#Just Normal
tns1st <-tni2tnsPreprocess(tni = rtni1st, regulatoryElements = c("TRPS1"), time = "time", 
                           event = "event", keycovar =c("Age","Grade"), 
                           excludeAttribs = c("LumA", "LumB", "Her2", "Basal"))
tns1st <-tnsGSEA2(tns1st)

tns2nd <-tni2tnsPreprocess(tni = rtni2nd, regulatoryElements = c("TRPS1"), time = "time", 
                           event = "event", keycovar =c("Age","Grade"), 
                           excludeAttribs = c("LumA", "LumB", "Her2", "Basal"))
tns2nd <-tnsGSEA2(tns2nd)

#Merge
tns_both = tns1st
tns_both@survivalData <- rbind(tns1st@survivalData[,-ncol(tns1st@survivalData)], tns2nd@survivalData)
tns_both@results$regulonActivity$differential = rbind(tns1st@results$regulonActivity$differential,
                                                      tns2nd@results$regulonActivity$differential)
tns_both@results$regulonActivity$positive = rbind(tns1st@results$regulonActivity$positive,
                                                  tns2nd@results$regulonActivity$positive)
tns_both@results$regulonActivity$negative = rbind(tns1st@results$regulonActivity$negative,
                                                  tns2nd@results$regulonActivity$negative)
tns_both@results$regulonActivity$status = rbind(tns1st@results$regulonActivity$status,
                                                tns2nd@results$regulonActivity$status)

#Get regulon activity and sample attributes
regact_gsea <-tnsGet(tns_both, "regulonActivity")$dif
sdata <-tnsGet(tns_both, "survivalData")
attribs <-c("ER+", "ER-","LumA","LumB","Basal","Her2","Normal")

#Run KM and Cox analysis
tns_both <-tnsKM(tns_both)
tns_both <-tnsCox(tns_both)

#Logrank p-value 
pdf("RTNsurvival_TRPS1_regulon_merged_METABRIC_after_GSEA_30minutes_FDR_0.1_no_endpoint_just_Normal.pdf", height = 3, width = 6)
tnsPlotKM(tns_both, regs = "TRPS1", attribs = attribs, panelWidths=c(3,1,4), width = 6)
dev.off()



#Just Her2-amplified
tns1st <-tni2tnsPreprocess(tni = rtni1st, regulatoryElements = c("TRPS1"), time = "time", 
                           event = "event", keycovar =c("Age","Grade"), 
                           excludeAttribs = c("LumA", "LumB", "Normal", "Basal"))
tns1st <-tnsGSEA2(tns1st)

tns2nd <-tni2tnsPreprocess(tni = rtni2nd, regulatoryElements = c("TRPS1"), time = "time", 
                           event = "event", keycovar =c("Age","Grade"), 
                           excludeAttribs = c("LumA", "LumB", "Normal", "Basal"))
tns2nd <-tnsGSEA2(tns2nd)

#Merge
tns_both = tns1st
tns_both@survivalData <- rbind(tns1st@survivalData[,-ncol(tns1st@survivalData)], tns2nd@survivalData)
tns_both@results$regulonActivity$differential = rbind(tns1st@results$regulonActivity$differential,
                                                      tns2nd@results$regulonActivity$differential)
tns_both@results$regulonActivity$positive = rbind(tns1st@results$regulonActivity$positive,
                                                  tns2nd@results$regulonActivity$positive)
tns_both@results$regulonActivity$negative = rbind(tns1st@results$regulonActivity$negative,
                                                  tns2nd@results$regulonActivity$negative)
tns_both@results$regulonActivity$status = rbind(tns1st@results$regulonActivity$status,
                                                tns2nd@results$regulonActivity$status)

#Get regulon activity and sample attributes
regact_gsea <-tnsGet(tns_both, "regulonActivity")$dif
sdata <-tnsGet(tns_both, "survivalData")
attribs <-c("ER+", "ER-","LumA","LumB","Basal","Her2","Normal")

#Run KM and Cox analysis
tns_both <-tnsKM(tns_both)
tns_both <-tnsCox(tns_both)

#Logrank p-value 
pdf("RTNsurvival_TRPS1_regulon_merged_METABRIC_after_GSEA_30minutes_FDR_0.1_no_endpoint_just_HER2.pdf", height = 3, width = 6)
tnsPlotKM(tns_both, regs = "TRPS1", attribs = attribs, panelWidths=c(3,1,4), width = 6)
dev.off()




#Just luminal A
tns1st <-tni2tnsPreprocess(tni = rtni1st, regulatoryElements = c("TRPS1"), time = "time", 
                           event = "event", keycovar =c("Age","Grade"), 
                           excludeAttribs = c("Basal", "Her2", "Normal", "LumB"))
tns1st <-tnsGSEA2(tns1st)

tns2nd <-tni2tnsPreprocess(tni = rtni2nd, regulatoryElements = c("TRPS1"), time = "time", 
                           event = "event", keycovar =c("Age","Grade"), 
                           excludeAttribs = c("Basal", "Her2", "Normal", "LumB"))
tns2nd <-tnsGSEA2(tns2nd)

#Merge
tns_both = tns1st
tns_both@survivalData <- rbind(tns1st@survivalData[,-ncol(tns1st@survivalData)], tns2nd@survivalData)
tns_both@results$regulonActivity$differential = rbind(tns1st@results$regulonActivity$differential,
                                                      tns2nd@results$regulonActivity$differential)
tns_both@results$regulonActivity$positive = rbind(tns1st@results$regulonActivity$positive,
                                                  tns2nd@results$regulonActivity$positive)
tns_both@results$regulonActivity$negative = rbind(tns1st@results$regulonActivity$negative,
                                                  tns2nd@results$regulonActivity$negative)
tns_both@results$regulonActivity$status = rbind(tns1st@results$regulonActivity$status,
                                                tns2nd@results$regulonActivity$status)

#Get regulon activity and sample attributes
regact_gsea <-tnsGet(tns_both, "regulonActivity")$dif
sdata <-tnsGet(tns_both, "survivalData")
attribs <-c("ER+", "ER-","LumA","LumB","Basal","Her2","Normal")

#Run KM and Cox analysis
tns_both <-tnsKM(tns_both)
tns_both <-tnsCox(tns_both)

#Logrank p-value 4.23e-4
pdf("RTNsurvival_TRPS1_regulon_merged_METABRIC_after_GSEA_30minutes_FDR_0.1_no_endpoint_just_luminal_A.pdf", height = 3, width = 6)
tnsPlotKM(tns_both, regs = "TRPS1", attribs = attribs, panelWidths=c(3,1,4), width = 6)
dev.off()



#Just luminal B
tns1st <-tni2tnsPreprocess(tni = rtni1st, regulatoryElements = c("TRPS1"), time = "time", 
                           event = "event", keycovar =c("Age","Grade"), 
                           excludeAttribs = c("Basal", "Her2", "Normal", "LumA"))
tns1st <-tnsGSEA2(tns1st)

tns2nd <-tni2tnsPreprocess(tni = rtni2nd, regulatoryElements = c("TRPS1"), time = "time", 
                           event = "event", keycovar =c("Age","Grade"), 
                           excludeAttribs = c("Basal", "Her2", "Normal", "LumA"))
tns2nd <-tnsGSEA2(tns2nd)

#Merge
tns_both = tns1st
tns_both@survivalData <- rbind(tns1st@survivalData[,-ncol(tns1st@survivalData)], tns2nd@survivalData)
tns_both@results$regulonActivity$differential = rbind(tns1st@results$regulonActivity$differential,
                                                      tns2nd@results$regulonActivity$differential)
tns_both@results$regulonActivity$positive = rbind(tns1st@results$regulonActivity$positive,
                                                  tns2nd@results$regulonActivity$positive)
tns_both@results$regulonActivity$negative = rbind(tns1st@results$regulonActivity$negative,
                                                  tns2nd@results$regulonActivity$negative)
tns_both@results$regulonActivity$status = rbind(tns1st@results$regulonActivity$status,
                                                tns2nd@results$regulonActivity$status)

#Get regulon activity and sample attributes
regact_gsea <-tnsGet(tns_both, "regulonActivity")$dif
sdata <-tnsGet(tns_both, "survivalData")
attribs <-c("ER+", "ER-","LumA","LumB","Basal","Her2","Normal")

#Run KM and Cox analysis
tns_both <-tnsKM(tns_both)
tns_both <-tnsCox(tns_both)

#Logrank p-value 2.34e-1
pdf("RTNsurvival_TRPS1_regulon_merged_METABRIC_after_GSEA_30minutes_FDR_0.1_no_endpoint_just_luminal_B.pdf", height = 3, width = 6)
tnsPlotKM(tns_both, regs = "TRPS1", attribs = attribs, panelWidths=c(3,1,4), width = 6)
dev.off()
```




